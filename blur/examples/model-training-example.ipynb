{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de10bae3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1393b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e755deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import itertools\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "\n",
    "from configs.xlmodelconfig import XlModelConfig\n",
    "from configs.fnetarmodelconfig import FnetarModelConfig\n",
    "from configs.feedbackmodelconfig import FeedbackModelConfig\n",
    "\n",
    "from configs.xladaptiveconfig import XlAdaptiveConfig\n",
    "from configs.feedbackadaptiveconfig import FeedbackAdaptiveConfig\n",
    "\n",
    "from configs.xldataconfig import XlDataConfig\n",
    "from configs.feedbackdataconfig import FeedbackDataConfig\n",
    "\n",
    "from configs.xloptimizerconfig import XlOptimizerConfig\n",
    "from configs.feedbackoptimizerconfig import FeedbackOptimizerConfig\n",
    "\n",
    "from configs.runconfig import RunConfig\n",
    "\n",
    "from blur import Blur\n",
    "\n",
    "from models.xl import Xl\n",
    "from models.fnetar import Fnetar\n",
    "from models.feedback import Feedback\n",
    "\n",
    "from modules.xlmemories import XlMemories\n",
    "from modules.feedbackmemories import FeedbackMemories\n",
    "\n",
    "from modules.adaptiveinput import AdaptiveInput\n",
    "from modules.adaptivelogsoftmax import AdaptiveLogSoftmax\n",
    "\n",
    "from utils.corpus import get_lm_corpus\n",
    "from utils.exp_utils import create_exp_dir\n",
    "\n",
    "from models.utils.normaluniforminitializer import NormalUniformInitializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb0f19",
   "metadata": {},
   "source": [
    "## Model and data arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "458a69d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Arguments:\n",
    "    model_name: str\n",
    "    dataset: str = 'wt103'\n",
    "    data: str = '../../data/wikitext-103'\n",
    "    cuda_device: str = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d6467",
   "metadata": {},
   "source": [
    "### Choose which model to train from ['xl', 'fnetar', 'feedback']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70aa1b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments(model_name='xl', dataset='wt103', data='../../data/wikitext-103', cuda_device='cuda')\n"
     ]
    }
   ],
   "source": [
    "args = Arguments(model_name = 'xl')\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6609337",
   "metadata": {},
   "source": [
    "## Setup checkpoint and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "706f4162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : LM-TFM\\20211106-150553\n",
      "RunConfig(work_dir='LM-TFM\\\\20211106-150553', cuda=True, seed=1111, log_interval=200, eval_interval=1000, debug=False, max_eval_steps=-1)\n"
     ]
    }
   ],
   "source": [
    "run_config = RunConfig()\n",
    "\n",
    "\n",
    "run_config.work_dir = os.path.join(run_config.work_dir, time.strftime('%Y%m%d-%H%M%S'))\n",
    "logging = create_exp_dir(run_config.work_dir, scripts_to_save=['../train.py', '../blur.py'], debug=run_config.debug)\n",
    "\n",
    "# Set the random seed manually for reproducibility.\n",
    "np.random.seed(run_config.seed)\n",
    "torch.manual_seed(run_config.seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if not run_config.cuda:\n",
    "        device = torch.device('cpu')\n",
    "        print('WARNING: You have a CUDA device, so you should probably run with --cuda')\n",
    "    else:\n",
    "        device = torch.device(args.cuda_device)\n",
    "        torch.cuda.manual_seed_all(run_config.seed)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d74108",
   "metadata": {},
   "source": [
    "## Load corpus and config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6bf1f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing dataset wt103...\n",
      "building vocab with min_freq=0, max_size=None\n",
      "final vocab size 267735 from 267734 unique tokens\n",
      "XlOptimizerConfig(max_step=200000, eta_min=0.0, clip=0.25, lr_min=0.0, decay_rate=0.5, warmup_step=0, scheduler='cosine', lr=0.00025, optim='adam')\n",
      "XlDataConfig(data='../data/wikitext-103', dataset='wt103', tgt_len=150, mem_len=150, batch_size=60, batch_chunk=10, eval_tgt_len=150, eval_mem_len=150, eval_batch_size=10, n_layer=16)\n",
      "XlAdaptiveConfig(d_model=410, n_classes=267735, cutoffs=[20000, 40000, 200000], div_value=1.0)\n",
      "XlModelConfig(n_layer=16, d_model=410, n_head=10, d_head=41, d_inner=2100, drop_out=0.1, drop_att=0.0, tgt_len=150, mem_len=150, same_length=False, clamp_len=-1)\n"
     ]
    }
   ],
   "source": [
    "corpus = get_lm_corpus(args.data, args.dataset)\n",
    "\n",
    "if args.model_name == 'xl':\n",
    "    optimizer_config = XlOptimizerConfig()\n",
    "    data_config = XlDataConfig()\n",
    "    adaptive_config = XlAdaptiveConfig(n_classes=len(corpus.vocab))\n",
    "    model_config = XlModelConfig()\n",
    "elif args.model_name == 'fnetar':\n",
    "    optimizer_config = XlOptimizerConfig()\n",
    "    data_config = XlDataConfig()\n",
    "    adaptive_config = XlAdaptiveConfig(n_classes=len(corpus.vocab))\n",
    "    model_config = FnetarModelConfig()\n",
    "elif args.model_name == 'feedback':\n",
    "    optimizer_config = FeedbackOptimizerConfig()\n",
    "    data_config = FeedbackDataConfig()\n",
    "    adaptive_config = FeedbackAdaptiveConfig(n_classes=len(corpus.vocab))\n",
    "    model_config = FeedbackModelConfig()\n",
    "else:\n",
    "    raise ValueError\n",
    "    \n",
    "assert data_config.batch_size % data_config.batch_chunk == 0\n",
    "\n",
    "print(optimizer_config)\n",
    "print(data_config)\n",
    "print(adaptive_config)\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbaa866",
   "metadata": {},
   "source": [
    "## Load data and construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b88623c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_iter = corpus.get_iterator('train', data_config.batch_size, data_config.tgt_len,\n",
    "    device=device, ext_len=0)\n",
    "va_iter = corpus.get_iterator('valid', data_config.eval_batch_size, data_config.eval_tgt_len,\n",
    "    device=device, ext_len=0)\n",
    "te_iter = corpus.get_iterator('test', data_config.eval_batch_size, data_config.eval_tgt_len,\n",
    "    device=device, ext_len=0)\n",
    "\n",
    "encoder = AdaptiveInput(**dataclasses.asdict(adaptive_config))\n",
    "decoder = AdaptiveLogSoftmax(**dataclasses.asdict(adaptive_config))\n",
    "\n",
    "if args.model_name == 'xl':\n",
    "    transformer = Xl(**dataclasses.asdict(model_config))\n",
    "elif args.model_name == 'fnetar':\n",
    "    transformer = Fnetar(**dataclasses.asdict(model_config))\n",
    "elif args.model_name == 'feedback':\n",
    "    transformer = Feedback(**dataclasses.asdict(model_config))\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "model = Blur(encoder=encoder, transformer=transformer, decoder=decoder, tie_weight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab77c832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "    - model_name : xl\n",
      "    - dataset : wt103\n",
      "    - data : ../../data/wikitext-103\n",
      "    - cuda_device : cuda\n",
      "    - n_all_param : 151107538\n",
      "    - n_nonemb_param : 41067220\n",
      "    - n_encoder_param : 109771350\n",
      "    - n_decoder_param : 110040318\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "initializer = NormalUniformInitializer()\n",
    "model.apply(initializer)\n",
    "model.encoder.apply(initializer) # ensure embedding init is not overridden by out_layer in case of weight sharing\n",
    "\n",
    "args.n_all_param = sum([p.nelement() for p in model.parameters()])\n",
    "args.n_nonemb_param = sum([p.nelement() for p in model.transformer.parameters()])\n",
    "args.n_encoder_param = sum([p.nelement() for p in model.encoder.parameters()])\n",
    "args.n_decoder_param = sum([p.nelement() for p in model.decoder.parameters()])\n",
    "\n",
    "para_model = model.to(device)\n",
    "\n",
    "#### optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=optimizer_config.lr)\n",
    "\n",
    "#### scheduler\n",
    "# here we do not set eta_min to lr_min to be backward compatible\n",
    "# because in previous versions eta_min is default to 0\n",
    "# rather than the default value of lr_min 1e-6\n",
    "if optimizer_config.scheduler == 'cosine':\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "        optimizer_config.max_step, eta_min=optimizer_config.eta_min) # should use eta_min arg\n",
    "elif optimizer_config.scheduler == 'inv_sqrt':\n",
    "    def lr_lambda(step):\n",
    "        # return a multiplier instead of a learning rate\n",
    "        if step == 0 and optimizer_config.warmup_step == 0:\n",
    "            return 1.\n",
    "        else:\n",
    "            return 1. / (step ** 0.5) if step > optimizer_config.warmup_step \\\n",
    "                   else step / (optimizer_config.warmup_step ** 1.5)\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "logging('=' * 100)\n",
    "for k, v in args.__dict__.items():\n",
    "    logging('    - {} : {}'.format(k, v))\n",
    "logging('=' * 100)\n",
    "# logging('#params = {}'.format(args.n_all_param))\n",
    "# logging('#non emb params = {}'.format(args.n_nonemb_param))\n",
    "# logging('#encoder params = {}'.format(args.n_encoder_param))\n",
    "# logging('#decoder params = {}'.format(args.n_decoder_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb76db7a",
   "metadata": {},
   "source": [
    "## Define training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c579a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Turn on training mode which enables dropout.\n",
    "    global train_step, train_loss, best_val_loss, eval_start_time, log_start_time\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    if args.model_name == 'xl' or args.model_name == 'fnetar':\n",
    "        memories = XlMemories(\n",
    "            n_stream=data_config.batch_chunk,\n",
    "            n_layer=data_config.n_layer,\n",
    "            tgt_len=data_config.tgt_len,\n",
    "            mem_len=data_config.mem_len,\n",
    "            ext_len=0,\n",
    "            dtype=next(model.parameters()).dtype\n",
    "        )\n",
    "    else:\n",
    "        memories = FeedbackMemories(n_stream=data_config.batch_chunk)\n",
    "\n",
    "    train_iter = tr_iter\n",
    "    for batch, (data, target, seq_len) in tqdm(\n",
    "        enumerate(train_iter), \n",
    "        total = train_iter.n_batch\n",
    "#         total=len(train_iter) // (data_config.batch_chunk * data_config.batch_size)\n",
    "    ):\n",
    "        model.zero_grad()\n",
    "\n",
    "        data_chunks = torch.chunk(data, data_config.batch_chunk, 0)\n",
    "        target_chunks = torch.chunk(target, data_config.batch_chunk, 0)\n",
    "        for i in range(data_config.batch_chunk):\n",
    "            data_i = data_chunks[i]\n",
    "            target_i = target_chunks[i]\n",
    "            memory_i = memories[i]\n",
    "            loss, new_memory_i = para_model(data_i, target_i, memory_i)\n",
    "            memories.update_memory_stream(stream_index=i, memory=new_memory_i)\n",
    "\n",
    "            loss = loss.float().mean().type_as(loss) / data_config.batch_chunk\n",
    "            loss.backward()\n",
    "            train_loss += loss.float().item()\n",
    "\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), optimizer_config.clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # step-wise learning rate annealing\n",
    "        train_step += 1\n",
    "\n",
    "        # linear warmup stage\n",
    "        if train_step < optimizer_config.warmup_step:\n",
    "            curr_lr = optimizer_config.lr * train_step / optimizer_config.warmup_step\n",
    "            optimizer.param_groups[0]['lr'] = curr_lr\n",
    "\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "        if train_step % run_config.log_interval == 0:\n",
    "            cur_loss = train_loss / run_config.log_interval\n",
    "            elapsed = time.time() - log_start_time\n",
    "            log_str = '| epoch {:3d} step {:>8d} | {:>6d} batches | lr {:.3g} ' \\\n",
    "                      '| ms/batch {:5.2f} | loss {:5.2f}'.format(\n",
    "                epoch, train_step, batch+1, optimizer.param_groups[0]['lr'],\n",
    "                elapsed * 1000 / run_config.log_interval, cur_loss)\n",
    "            log_str += ' | ppl {:9.3f}'.format(math.exp(cur_loss))\n",
    "            logging(log_str)\n",
    "            train_loss = 0\n",
    "            log_start_time = time.time()\n",
    "\n",
    "        if train_step % run_config.eval_interval == 0:\n",
    "            val_loss = evaluate(va_iter)\n",
    "            logging('-' * 100)\n",
    "            log_str = '| Eval {:3d} at step {:>8d} | time: {:5.2f}s ' \\\n",
    "                      '| valid loss {:5.2f}'.format(\n",
    "                train_step // run_config.eval_interval, train_step,\n",
    "                (time.time() - eval_start_time), val_loss)\n",
    "            log_str += ' | valid ppl {:9.3f}'.format(math.exp(val_loss))\n",
    "            logging(log_str)\n",
    "            logging('-' * 100)\n",
    "            # Save the model if the validation loss is the best we've seen so far.\n",
    "            if not best_val_loss or val_loss < best_val_loss:\n",
    "                if not run_config.debug:\n",
    "                    with open(os.path.join(run_config.work_dir, 'model.pt'), 'wb') as f:\n",
    "                        torch.save(model, f)\n",
    "                    with open(os.path.join(run_config.work_dir, 'optimizer.pt'), 'wb') as f:\n",
    "                        torch.save(optimizer.state_dict(), f)\n",
    "                best_val_loss = val_loss\n",
    "\n",
    "            eval_start_time = time.time()\n",
    "\n",
    "        if train_step == optimizer_config.max_step:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2965150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(eval_iter):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluation\n",
    "    total_len, total_loss = 0, 0.\n",
    "\n",
    "    if args.model_name == 'xl' or args.model_name == 'fnetar':\n",
    "        eval_memories = XlMemories(\n",
    "            n_stream=1,\n",
    "            n_layer=data_config.n_layer,\n",
    "            tgt_len=data_config.eval_tgt_len,\n",
    "            mem_len=data_config.eval_mem_len,\n",
    "            ext_len=0,\n",
    "            dtype=next(model.parameters()).dtype\n",
    "        )\n",
    "    else:\n",
    "        eval_memories = FeedbackMemories(n_stream=1)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (data, target, seq_len) in enumerate(eval_iter):\n",
    "            if run_config.max_eval_steps > 0 and i >= run_config.max_eval_steps:\n",
    "                break\n",
    "            loss, new_eval_memory = model(data, target, eval_memories[0])\n",
    "            eval_memories.update_memory_stream(stream_index=0, memory=new_eval_memory)\n",
    "\n",
    "            loss = loss.mean()\n",
    "            total_loss += seq_len * loss.float().item()\n",
    "            total_len += seq_len\n",
    "\n",
    "    # Switch back to the training mode\n",
    "    model.train()\n",
    "\n",
    "    return total_loss / total_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35cfc1e",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cf1fcc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                                          | 200/11470 [04:06<3:58:11,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step      200 |    200 batches | lr 0.00025 | ms/batch 1232.33 | loss  6.94 | ppl  1029.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▋                                                                         | 400/11470 [08:06<3:42:53,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step      400 |    400 batches | lr 0.00025 | ms/batch 1197.71 | loss  6.01 | ppl   409.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▉                                                                        | 600/11470 [12:06<3:39:14,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step      600 |    600 batches | lr 0.00025 | ms/batch 1202.98 | loss  5.68 | ppl   292.134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▎                                                                      | 800/11470 [16:08<3:32:24,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step      800 |    800 batches | lr 0.00025 | ms/batch 1208.36 | loss  5.47 | ppl   237.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▎                                                                      | 803/11470 [16:11<3:33:17,  1.20s/it]"
     ]
    }
   ],
   "source": [
    "# Loop over epochs.\n",
    "train_step = 0\n",
    "train_loss = 0\n",
    "best_val_loss = None\n",
    "\n",
    "log_start_time = time.time()\n",
    "eval_start_time = time.time()\n",
    "\n",
    "# At any point you can hit Ctrl + C to break out of training early.\n",
    "try:\n",
    "    for epoch in itertools.count(start=1):\n",
    "        train()\n",
    "        if train_step == optimizer_config.max_step:\n",
    "            logging('-' * 100)\n",
    "            logging('End of training')\n",
    "            break\n",
    "except KeyboardInterrupt:\n",
    "    logging('-' * 100)\n",
    "    logging('Exiting from training early')\n",
    "\n",
    "# Load the best saved model.\n",
    "with open(os.path.join(run_config.work_dir, 'model.pt'), 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "para_model = model.to(device)\n",
    "\n",
    "# Run on test data.\n",
    "test_loss = evaluate(te_iter)\n",
    "logging('=' * 100)\n",
    "\n",
    "logging('| End of training | test loss {:5.2f} | test ppl {:9.3f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "logging('=' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6501ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
