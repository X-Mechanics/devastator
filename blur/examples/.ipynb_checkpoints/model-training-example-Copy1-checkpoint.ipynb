{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de10bae3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1393b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e755deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import itertools\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "\n",
    "from configs.xlmodelconfig import XlModelConfig\n",
    "from configs.fnetarmodelconfig import FnetarModelConfig\n",
    "from configs.feedbackmodelconfig import FeedbackModelConfig\n",
    "\n",
    "from configs.xladaptiveconfig import XlAdaptiveConfig\n",
    "from configs.feedbackadaptiveconfig import FeedbackAdaptiveConfig\n",
    "\n",
    "from configs.xldataconfig import XlDataConfig\n",
    "from configs.feedbackdataconfig import FeedbackDataConfig\n",
    "\n",
    "from configs.xloptimizerconfig import XlOptimizerConfig\n",
    "from configs.feedbackoptimizerconfig import FeedbackOptimizerConfig\n",
    "\n",
    "from configs.runconfig import RunConfig\n",
    "\n",
    "from blur import Blur\n",
    "\n",
    "from models.xl import Xl\n",
    "from models.fnetar import Fnetar\n",
    "from models.feedback import Feedback\n",
    "\n",
    "from modules.xlmemories import XlMemories\n",
    "from modules.feedbackmemories import FeedbackMemories\n",
    "\n",
    "from modules.adaptiveinput import AdaptiveInput\n",
    "from modules.adaptivelogsoftmax import AdaptiveLogSoftmax\n",
    "\n",
    "from utils.data_utils import get_lm_corpus\n",
    "from utils.exp_utils import create_exp_dir\n",
    "\n",
    "from models.utils.normaluniforminitializer import NormalUniformInitializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb0f19",
   "metadata": {},
   "source": [
    "## Model and data arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "458a69d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Arguments:\n",
    "    model_name: str\n",
    "    dataset: str = 'wt103'\n",
    "    data: str = '../../data/wikitext-103'\n",
    "    cuda_device: str = 'cuda:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d6467",
   "metadata": {},
   "source": [
    "### Choose which model to train from ['xl', 'fnetar', 'feedback']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70aa1b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments(model_name='feedback', dataset='wt103', data='../../data/wikitext-103', cuda_device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "args = Arguments(model_name = 'feedback')\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6609337",
   "metadata": {},
   "source": [
    "## Setup checkpoint and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "706f4162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : LM-TFM\\20211028-171956\n",
      "RunConfig(work_dir='LM-TFM\\\\20211028-171956', cuda=True, seed=1111, log_interval=200, eval_interval=1000, debug=False, max_eval_steps=-1)\n"
     ]
    }
   ],
   "source": [
    "run_config = RunConfig()\n",
    "\n",
    "\n",
    "run_config.work_dir = os.path.join(run_config.work_dir, time.strftime('%Y%m%d-%H%M%S'))\n",
    "logging = create_exp_dir(run_config.work_dir, scripts_to_save=['../train.py', '../blur.py'], debug=run_config.debug)\n",
    "\n",
    "# Set the random seed manually for reproducibility.\n",
    "np.random.seed(run_config.seed)\n",
    "torch.manual_seed(run_config.seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if not run_config.cuda:\n",
    "        device = torch.device('cpu')\n",
    "        print('WARNING: You have a CUDA device, so you should probably run with --cuda')\n",
    "    else:\n",
    "        device = torch.device(args.cuda_device)\n",
    "        torch.cuda.manual_seed_all(run_config.seed)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(run_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d74108",
   "metadata": {},
   "source": [
    "## Load corpus and config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6bf1f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dataset...\n",
      "FeedbackOptimizerConfig(max_step=200000, eta_min=0.0, clip=0.1, lr_min=0.0, decay_rate=0.5, warmup_step=8000, scheduler='inv_sqrt', lr=0.0007, optim='adam')\n",
      "FeedbackDataConfig(data='../data/wikitext-103', dataset='wt103', tgt_len=150, mem_len=None, batch_size=60, batch_chunk=15, eval_tgt_len=256, eval_mem_len=256, eval_batch_size=10, n_layer=4)\n",
      "FeedbackAdaptiveConfig(d_model=512, n_classes=267735, cutoffs=[20000, 40000, 200000], div_value=1.0)\n",
      "FeedbackModelConfig(n_layer=4, d_model=512, n_head=8, d_head=128, d_inner=2048, drop_out=0.1, drop_att=0.0, tgt_len=2, mem_len=256)\n"
     ]
    }
   ],
   "source": [
    "corpus = get_lm_corpus(args.data, args.dataset)\n",
    "\n",
    "if args.model_name == 'xl':\n",
    "    optimizer_config = XlOptimizerConfig()\n",
    "    data_config = XlDataConfig()\n",
    "    adaptive_config = XlAdaptiveConfig(n_classes=len(corpus.vocab))\n",
    "    model_config = XlModelConfig()\n",
    "elif args.model_name == 'fnetar':\n",
    "    optimizer_config = XlOptimizerConfig()\n",
    "    data_config = XlDataConfig()\n",
    "    adaptive_config = XlAdaptiveConfig(n_classes=len(corpus.vocab))\n",
    "    model_config = FnetarModelConfig()\n",
    "elif args.model_name == 'feedback':\n",
    "    optimizer_config = FeedbackOptimizerConfig()\n",
    "    data_config = FeedbackDataConfig()\n",
    "    adaptive_config = FeedbackAdaptiveConfig(n_classes=len(corpus.vocab))\n",
    "    model_config = FeedbackModelConfig()\n",
    "else:\n",
    "    raise ValueError\n",
    "    \n",
    "assert data_config.batch_size % data_config.batch_chunk == 0\n",
    "\n",
    "print(optimizer_config)\n",
    "print(data_config)\n",
    "print(adaptive_config)\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbaa866",
   "metadata": {},
   "source": [
    "## Load data and construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b88623c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_iter = corpus.get_iterator('train', data_config.batch_size, data_config.tgt_len,\n",
    "    device=device, ext_len=0)\n",
    "va_iter = corpus.get_iterator('valid', data_config.eval_batch_size, data_config.eval_tgt_len,\n",
    "    device=device, ext_len=0)\n",
    "te_iter = corpus.get_iterator('test', data_config.eval_batch_size, data_config.eval_tgt_len,\n",
    "    device=device, ext_len=0)\n",
    "\n",
    "encoder = AdaptiveInput(**dataclasses.asdict(adaptive_config))\n",
    "decoder = AdaptiveLogSoftmax(**dataclasses.asdict(adaptive_config))\n",
    "\n",
    "if args.model_name == 'xl':\n",
    "    transformer = Xl(**dataclasses.asdict(model_config))\n",
    "elif args.model_name == 'fnetar':\n",
    "    transformer = Fnetar(**dataclasses.asdict(model_config))\n",
    "elif args.model_name == 'feedback':\n",
    "    transformer = Feedback(**dataclasses.asdict(model_config))\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "model = Blur(encoder=encoder, transformer=transformer, decoder=decoder, tie_weight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab77c832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "    - model_name : feedback\n",
      "    - dataset : wt103\n",
      "    - data : ../../data/wikitext-103\n",
      "    - cuda_device : cuda:1\n",
      "    - n_all_param : 155204319\n",
      "    - n_nonemb_param : 17854725\n",
      "    - n_encoder_param : 137080320\n",
      "    - n_decoder_param : 137349594\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "initializer = NormalUniformInitializer()\n",
    "model.apply(initializer)\n",
    "model.encoder.apply(initializer) # ensure embedding init is not overridden by out_layer in case of weight sharing\n",
    "\n",
    "args.n_all_param = sum([p.nelement() for p in model.parameters()])\n",
    "args.n_nonemb_param = sum([p.nelement() for p in model.transformer.parameters()])\n",
    "args.n_encoder_param = sum([p.nelement() for p in model.encoder.parameters()])\n",
    "args.n_decoder_param = sum([p.nelement() for p in model.decoder.parameters()])\n",
    "\n",
    "para_model = model.to(device)\n",
    "\n",
    "#### optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=optimizer_config.lr)\n",
    "\n",
    "#### scheduler\n",
    "# here we do not set eta_min to lr_min to be backward compatible\n",
    "# because in previous versions eta_min is default to 0\n",
    "# rather than the default value of lr_min 1e-6\n",
    "if optimizer_config.scheduler == 'cosine':\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "        optimizer_config.max_step, eta_min=optimizer_config.eta_min) # should use eta_min arg\n",
    "elif optimizer_config.scheduler == 'inv_sqrt':\n",
    "    def lr_lambda(step):\n",
    "        # return a multiplier instead of a learning rate\n",
    "        if step == 0 and optimizer_config.warmup_step == 0:\n",
    "            return 1.\n",
    "        else:\n",
    "            return 1. / (step ** 0.5) if step > optimizer_config.warmup_step \\\n",
    "                   else step / (optimizer_config.warmup_step ** 1.5)\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "logging('=' * 100)\n",
    "for k, v in args.__dict__.items():\n",
    "    logging('    - {} : {}'.format(k, v))\n",
    "logging('=' * 100)\n",
    "# logging('#params = {}'.format(args.n_all_param))\n",
    "# logging('#non emb params = {}'.format(args.n_nonemb_param))\n",
    "# logging('#encoder params = {}'.format(args.n_encoder_param))\n",
    "# logging('#decoder params = {}'.format(args.n_decoder_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb76db7a",
   "metadata": {},
   "source": [
    "## Define training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c579a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Turn on training mode which enables dropout.\n",
    "    global train_step, train_loss, best_val_loss, eval_start_time, log_start_time\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    if args.model_name == 'xl' or args.model_name == 'fnetar':\n",
    "        memories = XlMemories(\n",
    "            n_stream=data_config.batch_chunk,\n",
    "            n_layer=data_config.n_layer,\n",
    "            tgt_len=data_config.tgt_len,\n",
    "            mem_len=data_config.mem_len,\n",
    "            ext_len=0,\n",
    "            dtype=next(model.parameters()).dtype\n",
    "        )\n",
    "    else:\n",
    "        memories = FeedbackMemories(n_stream=data_config.batch_chunk)\n",
    "\n",
    "    train_iter = tr_iter\n",
    "    for batch, (data, target, seq_len) in tqdm(\n",
    "        enumerate(train_iter), \n",
    "        total = train_iter.n_batch\n",
    "#         total=len(train_iter) // (data_config.batch_chunk * data_config.batch_size)\n",
    "    ):\n",
    "        model.zero_grad()\n",
    "\n",
    "        data_chunks = torch.chunk(data, data_config.batch_chunk, 0)\n",
    "        target_chunks = torch.chunk(target, data_config.batch_chunk, 0)\n",
    "        for i in range(data_config.batch_chunk):\n",
    "            data_i = data_chunks[i]\n",
    "            target_i = target_chunks[i]\n",
    "            memory_i = memories[i]\n",
    "            loss, new_memory_i = para_model(data_i, target_i, memory_i)\n",
    "            memories.update_memory_stream(stream_index=i, memory=new_memory_i)\n",
    "\n",
    "            loss = loss.float().mean().type_as(loss) / data_config.batch_chunk\n",
    "            loss.backward()\n",
    "            train_loss += loss.float().item()\n",
    "\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), optimizer_config.clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # step-wise learning rate annealing\n",
    "        train_step += 1\n",
    "\n",
    "        # linear warmup stage\n",
    "        if train_step < optimizer_config.warmup_step:\n",
    "            curr_lr = optimizer_config.lr * train_step / optimizer_config.warmup_step\n",
    "            optimizer.param_groups[0]['lr'] = curr_lr\n",
    "\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "        if train_step % run_config.log_interval == 0:\n",
    "            cur_loss = train_loss / run_config.log_interval\n",
    "            elapsed = time.time() - log_start_time\n",
    "            log_str = '| epoch {:3d} step {:>8d} | {:>6d} batches | lr {:.3g} ' \\\n",
    "                      '| ms/batch {:5.2f} | loss {:5.2f}'.format(\n",
    "                epoch, train_step, batch+1, optimizer.param_groups[0]['lr'],\n",
    "                elapsed * 1000 / run_config.log_interval, cur_loss)\n",
    "            log_str += ' | ppl {:9.3f}'.format(math.exp(cur_loss))\n",
    "            logging(log_str)\n",
    "            train_loss = 0\n",
    "            log_start_time = time.time()\n",
    "\n",
    "        if train_step % run_config.eval_interval == 0:\n",
    "            val_loss = evaluate(va_iter)\n",
    "            logging('-' * 100)\n",
    "            log_str = '| Eval {:3d} at step {:>8d} | time: {:5.2f}s ' \\\n",
    "                      '| valid loss {:5.2f}'.format(\n",
    "                train_step // run_config.eval_interval, train_step,\n",
    "                (time.time() - eval_start_time), val_loss)\n",
    "            log_str += ' | valid ppl {:9.3f}'.format(math.exp(val_loss))\n",
    "            logging(log_str)\n",
    "            logging('-' * 100)\n",
    "            # Save the model if the validation loss is the best we've seen so far.\n",
    "            if not best_val_loss or val_loss < best_val_loss:\n",
    "                if not run_config.debug:\n",
    "                    with open(os.path.join(run_config.work_dir, 'model.pt'), 'wb') as f:\n",
    "                        torch.save(model, f)\n",
    "                    with open(os.path.join(run_config.work_dir, 'optimizer.pt'), 'wb') as f:\n",
    "                        torch.save(optimizer.state_dict(), f)\n",
    "                best_val_loss = val_loss\n",
    "\n",
    "            eval_start_time = time.time()\n",
    "\n",
    "        if train_step == optimizer_config.max_step:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2965150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(eval_iter):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluation\n",
    "    total_len, total_loss = 0, 0.\n",
    "\n",
    "    if args.model_name == 'xl' or args.model_name == 'fnetar':\n",
    "        eval_memories = XlMemories(\n",
    "            n_stream=1,\n",
    "            n_layer=data_config.n_layer,\n",
    "            tgt_len=data_config.eval_tgt_len,\n",
    "            mem_len=data_config.eval_mem_len,\n",
    "            ext_len=0,\n",
    "            dtype=next(model.parameters()).dtype\n",
    "        )\n",
    "    else:\n",
    "        eval_memories = FeedbackMemories(n_stream=1)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (data, target, seq_len) in enumerate(eval_iter):\n",
    "            if run_config.max_eval_steps > 0 and i >= run_config.max_eval_steps:\n",
    "                break\n",
    "            loss, new_eval_memory = model(data, target, eval_memories[0])\n",
    "            eval_memories.update_memory_stream(stream_index=0, memory=new_eval_memory)\n",
    "\n",
    "            loss = loss.mean()\n",
    "            total_loss += seq_len * loss.float().item()\n",
    "            total_len += seq_len\n",
    "\n",
    "    # Switch back to the training mode\n",
    "    model.train()\n",
    "\n",
    "    return total_loss / total_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35cfc1e",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13cf1fcc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                                         | 200/11470 [45:41<43:54:36, 14.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step      200 |    200 batches | lr 1.75e-05 | ms/batch 13705.97 | loss  9.97 | ppl 21403.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▌                                                                      | 400/11470 [1:31:49<42:41:12, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step      400 |    400 batches | lr 3.5e-05 | ms/batch 13841.11 | loss  7.27 | ppl  1436.232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▊                                                                     | 600/11470 [2:17:59<41:45:16, 13.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step      600 |    600 batches | lr 5.25e-05 | ms/batch 13850.09 | loss  6.88 | ppl   976.289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████                                                                    | 800/11470 [3:03:59<40:49:05, 13.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step      800 |    800 batches | lr 7e-05 | ms/batch 13802.52 | loss  6.59 | ppl   730.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▎                                                                  | 999/11470 [3:50:20<42:09:56, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step     1000 |   1000 batches | lr 8.75e-05 | ms/batch 13976.28 | loss  6.37 | ppl   584.818\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval   1 at step     1000 | time: 13902.51s | valid loss  6.28 | valid ppl   534.457\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▌                                                                | 1200/11470 [4:40:12<41:20:34, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step     1200 |   1200 batches | lr 0.000105 | ms/batch 14887.27 | loss  6.23 | ppl   508.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████▊                                                               | 1400/11470 [5:28:38<40:37:45, 14.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step     1400 |   1400 batches | lr 0.000122 | ms/batch 14530.48 | loss  6.13 | ppl   457.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████                                                              | 1600/11470 [6:17:06<39:41:05, 14.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step     1600 |   1600 batches | lr 0.00014 | ms/batch 14537.00 | loss  6.03 | ppl   417.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████▎                                                            | 1800/11470 [7:05:25<38:49:45, 14.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step     1800 |   1800 batches | lr 0.000158 | ms/batch 14496.51 | loss  5.96 | ppl   388.440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████▌                                                           | 1999/11470 [7:53:31<38:10:29, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step     2000 |   2000 batches | lr 0.000175 | ms/batch 14502.28 | loss  5.88 | ppl   357.096\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval   2 at step     2000 | time: 14587.71s | valid loss  5.86 | valid ppl   351.327\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████▊                                                          | 2200/11470 [8:43:18<37:25:10, 14.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step     2200 |   2200 batches | lr 0.000193 | ms/batch 14865.02 | loss  5.80 | ppl   330.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████                                                         | 2400/11470 [9:31:41<36:26:51, 14.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step     2400 |   2400 batches | lr 0.00021 | ms/batch 14514.57 | loss  5.73 | ppl   307.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████                                                       | 2600/11470 [10:20:32<35:56:36, 14.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step     2600 |   2600 batches | lr 0.000228 | ms/batch 14651.14 | loss  5.64 | ppl   282.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████▎                                                     | 2800/11470 [11:08:51<35:00:47, 14.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step     2800 |   2800 batches | lr 0.000245 | ms/batch 14498.07 | loss  5.57 | ppl   261.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████▌                                                    | 2999/11470 [11:56:58<34:01:31, 14.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step     3000 |   3000 batches | lr 0.000263 | ms/batch 14505.22 | loss  5.52 | ppl   249.721\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval   3 at step     3000 | time: 14603.93s | valid loss  5.50 | valid ppl   243.815\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████▊                                                   | 3200/11470 [12:46:45<33:20:56, 14.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step     3200 |   3200 batches | lr 0.00028 | ms/batch 14862.11 | loss  5.45 | ppl   233.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████                                                  | 3400/11470 [13:35:05<32:29:01, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step     3400 |   3400 batches | lr 0.000297 | ms/batch 14502.16 | loss  5.41 | ppl   223.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████▎                                                | 3600/11470 [14:23:29<31:50:51, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 step     3600 |   3600 batches | lr 0.000315 | ms/batch 14521.26 | loss  5.34 | ppl   207.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████▎                                               | 3769/11470 [15:04:32<30:48:12, 14.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'LM-TFM\\\\20211028-171956\\\\log.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2d6b831974fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtrain_step\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0moptimizer_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_step\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-ed1d60402bc6>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mmemory_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_memory_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpara_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mmemories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_memory_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_memory_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[1;32mC:\\dev\\devastator\\blur\\blur.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, y, memory)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_memory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[1;32mC:\\dev\\devastator\\blur\\models\\feedback.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, memory)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[0mdec_outp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_inp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_emb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\devastator\\blur\\models\\feedback.py\u001b[0m in \u001b[0;36m_forward\u001b[1;34m(self, dec_inp, pos_emb, mems, dec_attn_mask)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mdec_outp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdec_outp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mhiddens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_outp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[1;32mC:\\dev\\devastator\\blur\\models\\feedbacklayer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, mem, position)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFeedbackMemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFeedbackPosition\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_emb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[1;32mC:\\dev\\devastator\\blur\\modules\\feedbackattention.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, memory, pos_emb)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mattn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_att\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'b h i j, b h j d -> b h i d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2d6b831974fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mlogging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Exiting from training early'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\devastator\\blur\\utils\\exp_utils.py\u001b[0m in \u001b[0;36mlogging\u001b[1;34m(s, log_path, print_, log_)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlog_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf_log\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mf_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'LM-TFM\\\\20211028-171956\\\\log.txt'"
     ]
    }
   ],
   "source": [
    "# Loop over epochs.\n",
    "train_step = 0\n",
    "train_loss = 0\n",
    "best_val_loss = None\n",
    "\n",
    "log_start_time = time.time()\n",
    "eval_start_time = time.time()\n",
    "\n",
    "# At any point you can hit Ctrl + C to break out of training early.\n",
    "try:\n",
    "    for epoch in itertools.count(start=1):\n",
    "        train()\n",
    "        if train_step == optimizer_config.max_step:\n",
    "            logging('-' * 100)\n",
    "            logging('End of training')\n",
    "            break\n",
    "except KeyboardInterrupt:\n",
    "    logging('-' * 100)\n",
    "    logging('Exiting from training early')\n",
    "\n",
    "# Load the best saved model.\n",
    "with open(os.path.join(run_config.work_dir, 'model.pt'), 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "para_model = model.to(device)\n",
    "\n",
    "# Run on test data.\n",
    "test_loss = evaluate(te_iter)\n",
    "logging('=' * 100)\n",
    "\n",
    "logging('| End of training | test loss {:5.2f} | test ppl {:9.3f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "logging('=' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6501ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
