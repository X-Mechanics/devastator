{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b352afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d30b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6bd81dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(0, dtype=torch.float, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f96e636",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7c31907b82be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_lm_corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_utils'"
     ]
    }
   ],
   "source": [
    "\n",
    "from data_utils import get_lm_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b9425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = get_lm_corpus(args.data, args.dataset)\n",
    "ntokens = len(corpus.vocab)\n",
    "args.n_token = ntokens\n",
    "\n",
    "eval_batch_size = 10\n",
    "tr_iter = corpus.get_iterator('train', args.batch_size, args.tgt_len,\n",
    "    device=device, ext_len=args.ext_len)\n",
    "va_iter = corpus.get_iterator('valid', eval_batch_size, args.eval_tgt_len,\n",
    "    device=device, ext_len=args.ext_len)\n",
    "te_iter = corpus.get_iterator('test', eval_batch_size, args.eval_tgt_len,\n",
    "    device=device, ext_len=args.ext_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca579fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "testy = tuple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ceb9059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eae9b91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1028f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class XlMask(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates, registers, and applies the attention score mask\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, l_q: int, l_k: int, same_length: bool):\n",
    "        super(XlMask, self).__init__()\n",
    "        self.l_q = l_q\n",
    "        self.l_k = l_k\n",
    "        self.same_length = same_length\n",
    "\n",
    "        self.attn_mask = nn.Parameter(self.make_mask().float())\n",
    "#         self.register_buffer('attn_mask', self.attn_mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = (1, 1, l_q, l_k)\n",
    "        mask = self.attn_mask[None, None, :, -x.size(-1):]\n",
    "        # print(x.shape, mask.shape)\n",
    "        x.masked_fill_(mask.to(x.device), -torch.finfo(x.dtype).max)\n",
    "        return x\n",
    "\n",
    "    def make_mask(self):\n",
    "        causal_mask = torch.ones(self.l_q, self.l_k).triu_(self.l_k - self.l_q + 1).bool()\n",
    "\n",
    "        if self.same_length:\n",
    "            causal_mask = causal_mask + torch.ones(self.l_q, self.l_k).tril_(0).bool()\n",
    "        return causal_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47cb854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testy = XlMask(l_q=3, l_k=6, same_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae025c96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5ebef6c9f0ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tes' is not defined"
     ]
    }
   ],
   "source": [
    "tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29537366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.dtype"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(next(testy.parameters()).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70657c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10bb76a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False,  True,  True],\n",
       "        [ True,  True, False, False, False,  True],\n",
       "        [ True,  True,  True, False, False, False]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy.make_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9043637",
   "metadata": {},
   "outputs": [],
   "source": [
    "qlen=3\n",
    "klen=5\n",
    "mlen=2\n",
    "mem_len=3\n",
    "word_emb = torch.Tensor(qlen, klen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f778c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "same_length=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aa38206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59dceed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_shift_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e103a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "if same_length:\n",
    "    all_ones = word_emb.new_ones(qlen, klen)\n",
    "    mask_len = klen - mem_len\n",
    "    if mask_len > 0:\n",
    "        mask_shift_len = qlen - mask_len\n",
    "    else:\n",
    "        mask_shift_len = qlen\n",
    "    dec_attn_mask = (torch.triu(all_ones, 1+mlen)\n",
    "            + torch.tril(all_ones, -mask_shift_len)).byte()[:, :, None] # -1\n",
    "else:\n",
    "    dec_attn_mask = torch.triu(\n",
    "        word_emb.new_ones(qlen, klen), diagonal=1+mlen).byte()[:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eef6a78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1, 1],\n",
       "        [1, 0, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_attn_mask[:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7e40c0",
   "metadata": {},
   "source": [
    "## Import external dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8767040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# import devastator.blur as blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9ed492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "CUDA_MAJOR = int(torch.version.cuda.split('.')[0])\n",
    "CUDA_MINOR = int(torch.version.cuda.split('.')[1])\n",
    "\n",
    "class XlFakeAdaptiveLogSoftmax(nn.Module):\n",
    "    def __init__(self, n_token, d_embed, d_proj, cutoffs, div_val=1, keep_order=False):\n",
    "        assert div_val==1\n",
    "        super(XlFakeAdaptiveLogSoftmax, self).__init__()\n",
    "\n",
    "        self.n_token = n_token\n",
    "        self.d_embed = d_embed\n",
    "        self.d_proj = d_proj\n",
    "\n",
    "        self.cutoffs = cutoffs + [n_token]\n",
    "        self.cutoff_ends = [0] + self.cutoffs\n",
    "        self.div_val = div_val\n",
    "\n",
    "        self.shortlist_size = self.cutoffs[0]\n",
    "        self.n_clusters = len(self.cutoffs) - 1\n",
    "        self.head_size = self.shortlist_size + self.n_clusters\n",
    "        \n",
    "        self.cluster_weight = nn.Parameter(torch.zeros(self.n_clusters, self.d_embed))\n",
    "        self.cluster_bias = nn.Parameter(torch.zeros(self.n_clusters))\n",
    "\n",
    "        if self.n_clusters > 0:\n",
    "            self.cluster_weight = nn.Parameter(torch.zeros(self.n_clusters, self.d_embed))\n",
    "            self.cluster_bias = nn.Parameter(torch.zeros(self.n_clusters))\n",
    "\n",
    "        self.out_layers = nn.ModuleList()\n",
    "        self.out_projs = nn.ParameterList([])\n",
    "\n",
    "        for i in range(len(self.cutoffs)):\n",
    "            if d_proj != d_embed:\n",
    "                self.out_projs.append(\n",
    "                    nn.Parameter(torch.Tensor(d_proj, d_embed))\n",
    "                )\n",
    "#             else:\n",
    "#                 self.out_projs.append(None)\n",
    "\n",
    "        self.out_layers.append(nn.Linear(d_embed, n_token))\n",
    "\n",
    "        self.keep_order = keep_order\n",
    "\n",
    "    def _compute_logit(self, hidden, weight, bias, proj):\n",
    "        logit = F.linear(hidden, weight, bias=bias)\n",
    "        \n",
    "        if proj is None:\n",
    "            logit = F.linear(hidden, weight, bias=bias)\n",
    "        else:\n",
    "            # if CUDA_MAJOR <= 9 and CUDA_MINOR <= 1:\n",
    "            proj_hid = F.linear(hidden, proj.t().contiguous())\n",
    "            logit = F.linear(proj_hid, weight, bias=bias)\n",
    "            # else:\n",
    "            #     logit = torch.einsum('bd,de,ev->bv', (hidden, proj, weight.t()))\n",
    "            #     if bias is not None:\n",
    "            #         logit = logit + bias\n",
    "\n",
    "        return logit\n",
    "\n",
    "    def forward(self, hidden, target, keep_order=False):\n",
    "        '''\n",
    "            hidden :: [len*bsz x d_proj]\n",
    "            target :: [len*bsz]\n",
    "        '''\n",
    "\n",
    "        if hidden.size(0) != target.size(0):\n",
    "            raise RuntimeError('Input and target should have the same size '\n",
    "                               'in the batch dimension.')\n",
    "\n",
    "        if self.n_clusters == 0:\n",
    "            logit = self._compute_logit(hidden, self.out_layers[0].weight,\n",
    "                                        self.out_layers[0].bias, self.out_projs[0])\n",
    "            nll = -F.log_softmax(logit, dim=-1) \\\n",
    "                    .gather(1, target.unsqueeze(1)).squeeze(1)\n",
    "        else:\n",
    "            # construct weights and biases\n",
    "            weights, biases = [], []\n",
    "            for i in range(len(self.cutoffs)):\n",
    "                if self.div_val == 1:\n",
    "                    l_idx, r_idx = self.cutoff_ends[i], self.cutoff_ends[i + 1]\n",
    "                    weight_i = self.out_layers[0].weight[l_idx:r_idx]\n",
    "                    bias_i = self.out_layers[0].bias[l_idx:r_idx]\n",
    "                else:\n",
    "                    weight_i = self.out_layers[i].weight\n",
    "                    bias_i = self.out_layers[i].bias\n",
    "\n",
    "                if i == 0:\n",
    "                    weight_i = torch.cat(\n",
    "                        [weight_i, self.cluster_weight], dim=0)\n",
    "                    bias_i = torch.cat(\n",
    "                        [bias_i, self.cluster_bias], dim=0)\n",
    "\n",
    "                weights.append(weight_i)\n",
    "                biases.append(bias_i)\n",
    "\n",
    "            head_weight, head_bias, head_proj = weights[0], biases[0], self.out_projs[0]\n",
    "\n",
    "            head_logit = self._compute_logit(hidden, head_weight, head_bias, head_proj)\n",
    "            head_logprob = F.log_softmax(head_logit, dim=1)\n",
    "\n",
    "            nll = torch.zeros_like(target,\n",
    "                    dtype=hidden.dtype, device=hidden.device)\n",
    "\n",
    "            offset = 0\n",
    "            cutoff_values = [0] + self.cutoffs\n",
    "            for i in range(len(cutoff_values) - 1):\n",
    "                l_idx, r_idx = cutoff_values[i], cutoff_values[i + 1]\n",
    "\n",
    "                mask_i = (target >= l_idx) & (target < r_idx)\n",
    "                indices_i = mask_i.nonzero().squeeze()\n",
    "\n",
    "                if indices_i.numel() == 0:\n",
    "                    continue\n",
    "\n",
    "                target_i = target.index_select(0, indices_i) - l_idx\n",
    "                head_logprob_i = head_logprob.index_select(0, indices_i)\n",
    "\n",
    "                if i == 0:\n",
    "                    logprob_i = head_logprob_i.gather(1, target_i[:,None]).squeeze(1)\n",
    "                else:\n",
    "                    weight_i, bias_i, proj_i = weights[i], biases[i], self.out_projs[i]\n",
    "\n",
    "                    hidden_i = hidden.index_select(0, indices_i)\n",
    "\n",
    "                    tail_logit_i = self._compute_logit(hidden_i, weight_i, bias_i, proj_i)\n",
    "                    tail_logprob_i = F.log_softmax(tail_logit_i, dim=1)\n",
    "\n",
    "                    logprob_i = head_logprob_i[:, -i] \\\n",
    "                              + tail_logprob_i.gather(1, target_i[:,None]).squeeze(1)\n",
    "\n",
    "                if (hasattr(self, 'keep_order') and self.keep_order) or keep_order:\n",
    "                    nll.index_copy_(0, indices_i, -logprob_i)\n",
    "                else:\n",
    "                    nll[offset:offset+logprob_i.size(0)].copy_(-logprob_i)\n",
    "\n",
    "                offset += logprob_i.size(0)\n",
    "\n",
    "        return nll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f83ab8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple\n",
    "from torch.nn import Sequential, ModuleList, Linear, Module\n",
    "\n",
    "_ASMoutput = namedtuple('ASMoutput', ['output', 'loss'])\n",
    "\n",
    "\n",
    "class AdaptiveLogSoftmaxWithLoss(Module):\n",
    "    def __init__(self, d_model, n_classes, cutoffs, div_value=4., head_bias=True, tail_drop=0.5):\n",
    "        super(AdaptiveLogSoftmaxWithLoss, self).__init__()\n",
    "\n",
    "        cutoffs = list(cutoffs)\n",
    "\n",
    "        if (cutoffs != sorted(cutoffs)) \\\n",
    "                or (min(cutoffs) <= 0) \\\n",
    "                or (max(cutoffs) > (n_classes - 1)) \\\n",
    "                or (len(set(cutoffs)) != len(cutoffs)) \\\n",
    "                or any([int(c) != c for c in cutoffs]):\n",
    "            raise ValueError(\"cutoffs should be a sequence of unique, positive \"\n",
    "                             \"integers sorted in an increasing order, where \"\n",
    "                             \"each value is between 1 and n_classes-1\")\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_classes = n_classes\n",
    "        self.cutoffs = cutoffs + [n_classes]\n",
    "        self.div_value = div_value\n",
    "        self.head_bias = head_bias\n",
    "        self.tail_drop = tail_drop\n",
    "\n",
    "        self.shortlist_size = self.cutoffs[0]\n",
    "        self.n_clusters = len(self.cutoffs) - 1\n",
    "        self.head_size = self.shortlist_size + self.n_clusters\n",
    "        \n",
    "\n",
    "        self.head = Linear(self.d_model, self.shortlist_size, bias=self.head_bias)\n",
    "        self.cluster = Linear(self.d_model, self.n_clusters, bias=True)\n",
    "        self.tail = ModuleList()\n",
    "\n",
    "        for i in range(self.n_clusters):\n",
    "            hsz = int(self.d_model // (self.div_value ** (i + 1)))\n",
    "            osz = self.cutoffs[i + 1] - self.cutoffs[i]\n",
    "            \n",
    "            projection = Sequential(\n",
    "                Linear(self.d_model, osz, bias=True),\n",
    "                nn.Dropout(self.tail_drop)\n",
    "            )\n",
    "            \n",
    "#             projection = Sequential(\n",
    "#                 Linear(self.d_model, hsz, bias=False),\n",
    "#                 Linear(hsz, osz, bias=False),\n",
    "#                 nn.Dropout(self.tail_drop)\n",
    "#             )\n",
    "\n",
    "            self.tail.append(projection)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.head.reset_parameters()\n",
    "        for i2h, h2o in self.tail:\n",
    "            i2h.reset_parameters()\n",
    "            h2o.reset_parameters()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.size(0) != target.size(0):\n",
    "            raise RuntimeError('Input and target should have the same size '\n",
    "                               'in the batch dimension.')\n",
    "\n",
    "        used_rows = 0\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        output = input.new_zeros(batch_size)\n",
    "        gather_inds = target.new_empty(batch_size)\n",
    "\n",
    "        cutoff_values = [0] + self.cutoffs\n",
    "        for i in range(len(cutoff_values) - 1):\n",
    "\n",
    "            low_idx = cutoff_values[i]\n",
    "            high_idx = cutoff_values[i + 1]\n",
    "\n",
    "            target_mask = (target >= low_idx) & (target < high_idx)\n",
    "            row_indices = target_mask.nonzero().squeeze()\n",
    "\n",
    "            if row_indices.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            if i == 0:\n",
    "                gather_inds.index_copy_(0, row_indices, target[target_mask])\n",
    "\n",
    "            else:\n",
    "                relative_target = target[target_mask] - low_idx\n",
    "                input_subset = input.index_select(0, row_indices)\n",
    "\n",
    "                cluster_output = self.tail[i - 1](input_subset)\n",
    "                cluster_index = self.shortlist_size + i - 1\n",
    "\n",
    "                gather_inds.index_fill_(0, row_indices, cluster_index)\n",
    "\n",
    "                cluster_logprob = F.log_softmax(cluster_output, dim=1)\n",
    "                local_logprob = cluster_logprob.gather(1, relative_target.unsqueeze(1))\n",
    "                output.index_copy_(0, row_indices, local_logprob.squeeze(1))\n",
    "\n",
    "            used_rows += row_indices.numel()\n",
    "\n",
    "        if used_rows != batch_size:\n",
    "            raise RuntimeError(\"Target values should be in [0, {}], \"\n",
    "                               \"but values in range [{}, {}] \"\n",
    "                               \"were found. \".format(self.n_classes - 1,\n",
    "                                                     target.min().item(),\n",
    "                                                     target.max().item()))\n",
    "\n",
    "        head_output = torch.cat([self.head(input), self.cluster(input)], dim=-1)\n",
    "        head_logprob = F.log_softmax(head_output, dim=1)\n",
    "        output += head_logprob.gather(1, gather_inds.unsqueeze(1)).squeeze()\n",
    "        loss = (-output).mean()\n",
    "\n",
    "        return _ASMoutput(output, loss)\n",
    "\n",
    "    def _get_full_log_prob(self, input, head_output):\n",
    "        \"\"\" Given input tensor, and output of `self.head`,\n",
    "        compute the log of the full distribution \"\"\"\n",
    "\n",
    "        out = input.new_empty((head_output.size(0), self.n_classes))\n",
    "        head_logprob = F.log_softmax(head_output, dim=1)\n",
    "\n",
    "        out[:, :self.shortlist_size] = head_logprob[:, :self.shortlist_size]\n",
    "\n",
    "        for i, (start_idx, stop_idx) in enumerate(zip(self.cutoffs, self.cutoffs[1:])):\n",
    "            cluster_output = self.tail[i](input)\n",
    "            cluster_logprob = F.log_softmax(cluster_output, dim=1)\n",
    "            output_logprob = cluster_logprob + head_logprob[:, self.shortlist_size + i].unsqueeze(1)\n",
    "\n",
    "            out[:, start_idx:stop_idx] = output_logprob\n",
    "\n",
    "        return out\n",
    "\n",
    "    def log_prob(self, input):\n",
    "        r\"\"\" Computes log probabilities for all :math:`\\texttt{n\\_classes}`\n",
    "        Args:\n",
    "            input (Tensor): a minibatch of examples\n",
    "        Returns:\n",
    "            log-probabilities of for each class :math:`c`\n",
    "            in range :math:`0 <= c <= \\texttt{n\\_classes}`, where :math:`\\texttt{n\\_classes}` is a\n",
    "            parameter passed to ``AdaptiveLogSoftmaxWithLoss`` constructor.\n",
    "        Shape:\n",
    "            - Input: :math:`(N, \\texttt{in\\_features})`\n",
    "            - Output: :math:`(N, \\texttt{n\\_classes})`\n",
    "        \"\"\"\n",
    "\n",
    "        head_output = torch.cat([self.head(input), self.cluster(input)], dim=-1)\n",
    "        return self._get_full_log_prob(input, head_output)\n",
    "\n",
    "    def predict(self, input):\n",
    "        r\"\"\" This is equivalent to `self.log_pob(input).argmax(dim=1)`,\n",
    "        but is more efficient in some cases.\n",
    "        Args:\n",
    "            input (Tensor): a minibatch of examples\n",
    "        Returns:\n",
    "            output (Tensor): a class with the highest probability for each example\n",
    "        Shape:\n",
    "            - Input: :math:`(N, \\texttt{in\\_features})`\n",
    "            - Output: :math:`(N)`\n",
    "        \"\"\"\n",
    "\n",
    "        head_output = torch.cat([self.head(input), self.cluster(input)], dim=-1)\n",
    "        output = torch.argmax(head_output, dim=1)\n",
    "        not_in_shortlist = (output >= self.shortlist_size)\n",
    "        all_in_shortlist = not (not_in_shortlist.any())\n",
    "\n",
    "        if all_in_shortlist:\n",
    "            return output\n",
    "\n",
    "        elif not_in_shortlist.all():\n",
    "            log_prob = self._get_full_log_prob(input, head_output)\n",
    "            return torch.argmax(log_prob, dim=1)\n",
    "\n",
    "        else:\n",
    "            log_prob = self._get_full_log_prob(input[not_in_shortlist],\n",
    "                                               head_output[not_in_shortlist])\n",
    "            output[not_in_shortlist] = torch.argmax(log_prob, dim=1)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723774a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveEmbedding(nn.Module):\n",
    "    def __init__(self, n_token, d_embed, d_proj, cutoffs, div_val=1, \n",
    "                 sample_softmax=False):\n",
    "        super(AdaptiveEmbedding, self).__init__()\n",
    "\n",
    "        self.n_token = n_token\n",
    "        self.d_embed = d_embed\n",
    "\n",
    "        self.cutoffs = cutoffs + [n_token]\n",
    "        self.div_val = div_val\n",
    "        self.d_proj = d_proj\n",
    "\n",
    "        self.emb_scale = d_proj ** 0.5\n",
    "\n",
    "        self.cutoff_ends = [0] + self.cutoffs\n",
    "\n",
    "        self.emb_layers = nn.ModuleList()\n",
    "        self.emb_projs = nn.ParameterList()\n",
    "        if div_val == 1:\n",
    "            self.emb_layers.append(\n",
    "                nn.Embedding(n_token, d_embed, sparse=sample_softmax>0)\n",
    "            )\n",
    "            if d_proj != d_embed:\n",
    "                self.emb_projs.append(nn.Parameter(torch.Tensor(d_proj, d_embed)))\n",
    "        else:\n",
    "            for i in range(len(self.cutoffs)):\n",
    "                l_idx, r_idx = self.cutoff_ends[i], self.cutoff_ends[i+1]\n",
    "                d_emb_i = d_embed // (div_val ** i)\n",
    "                self.emb_layers.append(nn.Embedding(r_idx-l_idx, d_emb_i))\n",
    "                self.emb_projs.append(nn.Parameter(torch.Tensor(d_proj, d_emb_i)))\n",
    "\n",
    "    def forward(self, inp):\n",
    "        if self.div_val == 1:\n",
    "            embed = self.emb_layers[0](inp)\n",
    "            if self.d_proj != self.d_embed:\n",
    "                embed  = F.linear(embed, self.emb_projs[0])\n",
    "        else:\n",
    "            param = next(self.parameters())\n",
    "            inp_flat = inp.view(-1)\n",
    "            emb_flat = torch.zeros([inp_flat.size(0), self.d_proj], \n",
    "                dtype=param.dtype, device=param.device)\n",
    "            for i in range(len(self.cutoffs)):\n",
    "                l_idx, r_idx = self.cutoff_ends[i], self.cutoff_ends[i + 1]\n",
    "\n",
    "                mask_i = (inp_flat >= l_idx) & (inp_flat < r_idx)\n",
    "                indices_i = mask_i.nonzero().squeeze()\n",
    "\n",
    "                if indices_i.numel() == 0:\n",
    "                    continue\n",
    "\n",
    "                inp_i = inp_flat.index_select(0, indices_i) - l_idx\n",
    "                emb_i = self.emb_layers[i](inp_i)\n",
    "                emb_i = F.linear(emb_i, self.emb_projs[i])\n",
    "\n",
    "                emb_flat.index_copy_(0, indices_i, emb_i)\n",
    "\n",
    "            embed = emb_flat.view(*inp.size(), self.d_proj)\n",
    "\n",
    "        embed.mul_(self.emb_scale)\n",
    "\n",
    "        return embed\n",
    "    \n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class AdaptiveInput(nn.Module):\n",
    "    def __init__(self, d_model, n_classes, cutoffs=None, div_value=2.0, head_bias=False, tail_drop=0.5):\n",
    "        super(AdaptiveInput, self).__init__()\n",
    "        if not cutoffs:\n",
    "            cutoffs = [5000, 10000]\n",
    "        cutoffs = list(cutoffs)\n",
    "\n",
    "        if (cutoffs != sorted(cutoffs)) \\\n",
    "                or (min(cutoffs) <= 0) \\\n",
    "                or (max(cutoffs) >= (n_classes - 1)) \\\n",
    "                or (len(set(cutoffs)) != len(cutoffs)) \\\n",
    "                or any([int(c) != c for c in cutoffs]):\n",
    "            raise ValueError(\"cutoffs should be a sequence of unique, positive \"\n",
    "                             \"integers sorted in an increasing order, where \"\n",
    "                             \"each value is between 1 and n_classes-1\")\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_classes = n_classes\n",
    "        self.cutoffs = cutoffs + [n_classes]\n",
    "        self.div_value = div_value\n",
    "        self.head_bias = head_bias\n",
    "        self.tail_drop = tail_drop\n",
    "\n",
    "        self.n_clusters = len(self.cutoffs) - 1\n",
    "        self.head_size = self.cutoffs[0]\n",
    "\n",
    "        #         self.head = nn.Sequential(nn.Embedding(self.head_size, self.in_features),\n",
    "        #                                   nn.Linear(self.in_features, self.in_features, bias=self.head_bias))\n",
    "\n",
    "        self.head = nn.Embedding(self.head_size, self.d_model)\n",
    "        #                                   nn.Linear(self.in_features, self.in_features, bias=self.head_bias))\n",
    "\n",
    "        self.tail = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.n_clusters):\n",
    "            hsz = int(self.d_model // (self.div_value ** (i + 1)))\n",
    "            osz = self.cutoffs[i + 1] - self.cutoffs[i]\n",
    "\n",
    "            projection = nn.Sequential(\n",
    "                nn.Embedding(osz, self.d_model),\n",
    "                nn.Dropout(self.tail_drop)\n",
    "            )\n",
    "            \n",
    "#             projection = nn.Sequential(\n",
    "#                 nn.Embedding(osz, hsz),\n",
    "#                 nn.Linear(hsz, self.d_model, bias=False),\n",
    "#                 nn.Dropout(self.tail_drop)\n",
    "#             )\n",
    "\n",
    "            self.tail.append(projection)\n",
    "\n",
    "    def forward(self, input):\n",
    "        used_rows = 0\n",
    "        input_size = list(input.size())\n",
    "\n",
    "        output = input.new_zeros([input.size(0) * input.size(1)] + [self.d_model]).float()\n",
    "        input = input.view(-1)\n",
    "\n",
    "        cutoff_values = [0] + self.cutoffs\n",
    "        for i in range(len(cutoff_values) - 1):\n",
    "\n",
    "            low_idx = cutoff_values[i]\n",
    "            high_idx = cutoff_values[i + 1]\n",
    "\n",
    "            input_mask = (input >= low_idx) & (input < high_idx)\n",
    "            row_indices = input_mask.nonzero().squeeze()\n",
    "\n",
    "            if row_indices.numel() == 0:\n",
    "                continue\n",
    "            out = self.head(input[input_mask] - low_idx) if i == 0 else self.tail[i - 1](input[input_mask] - low_idx)\n",
    "            output.index_copy_(0, row_indices, out)\n",
    "            used_rows += row_indices.numel()\n",
    "\n",
    "        return output.view(input_size[0], input_size[1], -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31463c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110040318"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "110040318"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([3, 410]),\n",
       " torch.Size([3]),\n",
       " torch.Size([267735, 410]),\n",
       " torch.Size([267735])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([20000, 410]),\n",
       " torch.Size([20000]),\n",
       " torch.Size([3, 410]),\n",
       " torch.Size([3]),\n",
       " torch.Size([20000, 410]),\n",
       " torch.Size([20000]),\n",
       " torch.Size([160000, 410]),\n",
       " torch.Size([160000]),\n",
       " torch.Size([67735, 410]),\n",
       " torch.Size([67735])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy1 = XlFakeAdaptiveLogSoftmax(\n",
    "    n_token=267735, d_embed=410, d_proj=410, cutoffs=[20000, 40000, 200000], div_val=1, keep_order=False)\n",
    "\n",
    "testy2 = AdaptiveLogSoftmaxWithLoss(\n",
    "    d_model=410, n_classes=267735, cutoffs=[20000, 40000, 200000], div_value=1, head_bias=True, tail_drop=0.5)\n",
    "\n",
    "sum([p.nelement() for p in testy1.parameters()])\n",
    "sum([p.nelement() for p in testy2.parameters()])\n",
    "[p.shape for p in testy1.parameters()]\n",
    "[p.shape for p in testy2.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "710784b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109771350"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "109771350"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([267735, 410])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([20000, 410]),\n",
       " torch.Size([20000, 410]),\n",
       " torch.Size([160000, 410]),\n",
       " torch.Size([67735, 410])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy3 = AdaptiveEmbedding(\n",
    "    n_token=267735, d_embed=410, d_proj=410, cutoffs=[20000, 40000, 200000], div_val=1)\n",
    "\n",
    "testy4 = AdaptiveInput(\n",
    "    d_model=410, n_classes=267735, cutoffs=[20000, 40000, 200000], div_value=1, head_bias=True, tail_drop=0.5)\n",
    "\n",
    "sum([p.nelement() for p in testy3.parameters()])\n",
    "sum([p.nelement() for p in testy4.parameters()])\n",
    "[p.shape for p in testy3.parameters()]\n",
    "[p.shape for p in testy4.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "193692a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0416, 0.0432, 0.0104], requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy2.cluster.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cad8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TESTYMODULE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TESTYMODULE, self).__init__()\n",
    "        self.enc = AdaptiveInput(\n",
    "    d_model=410, n_classes=267735, cutoffs=[20000, 40000, 200000], div_value=1, head_bias=True, tail_drop=0.5)\n",
    "        self.dec = AdaptiveLogSoftmaxWithLoss(\n",
    "    d_model=410, n_classes=267735, cutoffs=[20000, 40000, 200000], div_value=1, head_bias=True, tail_drop=0.5)\n",
    "        \n",
    "        self.enc.head.weight = self.dec.head.weight\n",
    "        \n",
    "        for i in range(len(self.enc.cutoffs) - 1):\n",
    "            self.enc.tail[i][0].weight = self.dec.tail[i][0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bf4ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TESTYMODULE2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TESTYMODULE2, self).__init__()\n",
    "        self.enc = AdaptiveEmbedding(\n",
    "    n_token=267735, d_embed=410, d_proj=410, cutoffs=[20000, 40000, 200000], div_val=1)\n",
    "        self.dec = XlFakeAdaptiveLogSoftmax(\n",
    "    n_token=267735, d_embed=410, d_proj=410, cutoffs=[20000, 40000, 200000], div_val=1, keep_order=False)\n",
    "        \n",
    "        for i in range(len(self.dec.out_layers)):\n",
    "            self.dec.out_layers[i].weight = self.enc.emb_layers[i].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab9d5587",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TESTYMODULE()\n",
    "test2 = TESTYMODULE2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eec47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6480c903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110040318"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "110040318"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.nelement() for p in test.parameters()])\n",
    "sum([p.nelement() for p in test2.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2f87758d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "088ac861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219811668"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "109771350+110040318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "22ca93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveLogSoftmaxWithLoss(\n",
       "  (head): Linear(in_features=16, out_features=8, bias=True)\n",
       "  (tail): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=5, bias=True)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=10, bias=True)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=80, bias=True)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6469a1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XlFakeAdaptiveLogSoftmax(\n",
       "  (out_layers): ModuleList(\n",
       "    (0): Linear(in_features=16, out_features=100, bias=True)\n",
       "  )\n",
       "  (out_projs): ParameterList()\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b7d760d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.3243,  0.2786, -0.2987, -0.2320,  0.0096,  0.2191, -0.2122, -0.0477,\n",
       "         0.0120,  0.0024,  0.3267, -0.0650,  0.0505, -0.0730, -0.2181,  0.0347,\n",
       "        -0.1497, -0.1301,  0.2085, -0.0538, -0.2919, -0.0457,  0.0772, -0.0679,\n",
       "        -0.1526, -0.1961,  0.2707, -0.3318, -0.1309, -0.0842, -0.0759, -0.0234,\n",
       "        -0.1012,  0.2653,  0.1860,  0.0778,  0.0813, -0.2292, -0.0140, -0.1118,\n",
       "         0.3174, -0.1351, -0.1146,  0.1701, -0.3057, -0.0196,  0.0559,  0.1809,\n",
       "         0.2349,  0.1497, -0.2351,  0.3413, -0.0569,  0.0025, -0.2674, -0.3436,\n",
       "        -0.2953, -0.0706, -0.3101,  0.2748, -0.1616, -0.0125,  0.0502, -0.1467,\n",
       "         0.2457, -0.1743, -0.1924, -0.1668,  0.1999,  0.3486, -0.2773,  0.0620,\n",
       "         0.0530, -0.0173,  0.0202, -0.1099, -0.1324, -0.2179,  0.3291,  0.0601,\n",
       "         0.3506,  0.2746, -0.0714, -0.1104, -0.2893, -0.3355, -0.3118,  0.0790,\n",
       "         0.3025, -0.0997,  0.1448,  0.3294,  0.2558,  0.3532, -0.2732, -0.0481,\n",
       "         0.3110, -0.1947,  0.3285, -0.0385], requires_grad=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(testy1.parameters())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2901e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy1.cluster_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0c9d3f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([100, 16])]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([5, 16]),\n",
       " torch.Size([5, 16]),\n",
       " torch.Size([10, 16]),\n",
       " torch.Size([80, 16])]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f60d5182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveEmbedding(\n",
       "  (emb_layers): ModuleList(\n",
       "    (0): Embedding(100, 16)\n",
       "  )\n",
       "  (emb_projs): ParameterList()\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5b19efdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveInput(\n",
       "  (head): Embedding(5, 16)\n",
       "  (tail): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Embedding(5, 16)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Embedding(10, 16)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Embedding(80, 16)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "185e5b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in list(testy3.emb_projs.parameters())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b85a1552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.7646e+00, -2.0763e+00, -5.5581e-01,  1.0202e-02,  1.3865e+00,\n",
       "           2.6699e-01, -4.4941e-01, -6.8863e-01],\n",
       "         [ 1.2469e+00, -2.6784e-01,  1.5360e+00, -4.4752e-01, -9.6451e-02,\n",
       "           3.8696e-01,  1.1121e+00, -1.4022e+00],\n",
       "         [ 2.0571e+00,  8.7153e-01,  1.2445e-01,  5.9801e-01, -1.2614e+00,\n",
       "          -6.9918e-01, -1.1213e+00, -1.0527e+00],\n",
       "         [-1.6042e-01, -2.5082e-01, -1.1320e+00, -2.8502e-01,  5.8993e-01,\n",
       "           1.3376e+00,  3.6441e-01, -3.3866e-02],\n",
       "         [-7.3730e-01, -8.2515e-01, -5.1168e-01,  9.2284e-01,  7.7886e-01,\n",
       "           9.3492e-01, -9.8698e-02,  1.6593e+00],\n",
       "         [-1.3181e+00, -1.7584e+00, -8.0182e-03, -3.4626e-01, -8.6113e-02,\n",
       "          -1.1796e+00, -2.0769e+00,  1.1412e+00],\n",
       "         [-9.0202e-01, -4.5570e-01, -1.1279e-01,  6.7027e-01,  5.2510e-01,\n",
       "           1.0503e+00,  7.3583e-01,  4.0013e-01],\n",
       "         [ 5.1278e-01, -1.1645e-01, -7.1604e-01,  3.9448e-01, -2.8525e-01,\n",
       "          -1.2453e+00, -9.0679e-01, -2.2781e+00],\n",
       "         [ 7.3215e-01,  1.9011e+00,  1.0959e-01, -7.7342e-01,  8.2227e-01,\n",
       "           1.1372e+00,  3.7865e-02,  2.1857e-01],\n",
       "         [ 1.9003e-01, -1.4160e+00, -1.5438e-01, -1.1784e+00, -8.5138e-01,\n",
       "           1.9697e-01, -1.8868e+00,  4.6209e-01],\n",
       "         [ 5.6353e-01,  1.3470e+00,  9.8223e-01,  5.3549e-01, -7.3149e-01,\n",
       "           1.1886e+00,  1.0058e+00,  6.2860e-01],\n",
       "         [ 7.9055e-01, -8.5577e-01, -5.0691e-01, -4.4676e-01,  1.2300e+00,\n",
       "          -4.6186e-01,  1.4028e+00, -3.4976e-01],\n",
       "         [-1.4035e+00, -2.0575e+00, -1.1295e+00, -3.1227e-01,  1.1120e-01,\n",
       "           1.4785e-01, -3.1319e-02,  6.8777e-01],\n",
       "         [ 1.9969e+00, -1.8385e+00,  4.9331e-01,  6.3131e-01,  5.7372e-02,\n",
       "          -6.7931e-01,  3.5773e-02,  2.8817e-01],\n",
       "         [ 5.3436e-01,  1.1925e+00, -1.5461e+00, -1.9661e-01,  8.4893e-01,\n",
       "           8.1538e-01,  3.0181e-01,  1.5100e+00],\n",
       "         [ 8.7327e-01, -1.6507e+00,  7.9407e-01,  8.0492e-02,  6.5898e-01,\n",
       "          -6.4462e-01, -9.4638e-02, -1.1838e+00],\n",
       "         [-5.8345e-01, -3.2998e-01,  3.8515e-01, -5.3675e-01,  7.4840e-01,\n",
       "          -1.6577e+00,  1.5799e-01, -4.7829e-01],\n",
       "         [-6.5668e-02, -1.0757e+00, -2.6907e+00,  4.2649e-01, -4.8671e-01,\n",
       "          -4.1503e-01,  8.6321e-01, -4.3313e-01],\n",
       "         [-4.1216e-01,  8.5747e-01, -4.7430e-01, -9.3157e-01, -1.6122e-01,\n",
       "           7.4683e-02, -1.9908e-01,  1.0639e+00],\n",
       "         [ 1.8085e-01, -1.2293e+00, -3.8818e-01, -9.3052e-01,  5.2287e-01,\n",
       "          -5.4978e-01, -8.3518e-01,  1.2861e+00],\n",
       "         [ 2.9314e-01, -1.6968e-01, -1.4820e+00,  3.8392e-01,  2.1815e+00,\n",
       "           2.6549e+00, -3.3726e-01,  1.5514e+00],\n",
       "         [ 4.3506e-01, -4.0823e-02, -6.9820e-01,  1.3676e+00,  1.5392e+00,\n",
       "           6.0597e-01, -9.2152e-01, -1.4414e+00],\n",
       "         [ 1.5850e-02,  1.1953e+00, -4.2235e-01, -4.1448e-01,  2.2536e-01,\n",
       "           1.9785e-01,  8.8279e-01,  2.0437e-01],\n",
       "         [ 4.6257e-01,  8.3303e-01, -1.2656e+00, -8.4642e-01, -2.4530e-01,\n",
       "           7.2508e-01, -6.5940e-01,  6.1081e-01],\n",
       "         [-1.4282e+00, -9.3882e-01,  6.5676e-01, -5.2577e-01, -1.3158e+00,\n",
       "           1.3738e-01,  8.7276e-01, -6.8356e-01],\n",
       "         [-1.6721e+00,  9.0671e-01, -1.2554e+00,  4.0065e-01, -7.2844e-01,\n",
       "          -4.0615e-01, -1.0480e+00,  3.0565e-01],\n",
       "         [ 1.0511e+00,  8.0543e-01,  2.0808e+00, -9.7697e-01, -2.6015e+00,\n",
       "          -6.3018e-01,  3.6060e-02,  4.1784e-01],\n",
       "         [-3.0768e-01,  7.6652e-01, -2.0362e-01,  1.5277e+00, -1.0388e+00,\n",
       "          -6.0288e-01,  8.4276e-02,  5.1306e-01],\n",
       "         [ 1.2292e-01, -1.4189e+00, -1.6070e+00,  5.0318e-01,  3.9877e-01,\n",
       "           1.7310e+00,  1.5263e+00,  6.6312e-01],\n",
       "         [ 1.7374e+00, -6.1829e-01,  7.7963e-01, -6.0022e-01,  4.0543e-01,\n",
       "          -7.9571e-01,  4.4200e-01, -1.8434e+00],\n",
       "         [ 1.9807e-01,  1.0553e+00,  9.4692e-01, -7.1317e-01, -5.4692e-03,\n",
       "          -5.9084e-01, -1.4236e+00,  1.0856e+00],\n",
       "         [-1.0716e+00,  8.7736e-01, -3.3339e-01,  8.1934e-01,  1.1592e+00,\n",
       "          -8.4426e-01, -4.6105e-01, -1.1672e-01],\n",
       "         [ 1.4421e+00,  1.5975e+00,  5.8569e-01, -3.3906e-01, -1.5562e+00,\n",
       "           8.0715e-01, -1.6257e+00,  7.7388e-01],\n",
       "         [ 2.2792e+00,  1.6962e+00, -1.2449e+00,  3.7500e-01, -1.3059e+00,\n",
       "           6.4149e-01,  7.5266e-01,  6.7913e-01],\n",
       "         [-8.3677e-01,  1.9569e-01, -2.5519e-01,  3.8313e-01,  1.0219e+00,\n",
       "          -6.6277e-01, -1.2964e+00,  7.6249e-01],\n",
       "         [-8.6077e-01,  5.2219e-01, -1.4067e+00,  2.1122e-01,  5.6363e-01,\n",
       "           1.0396e+00, -3.7580e-01,  1.7599e+00],\n",
       "         [ 6.0561e-01, -4.0257e-01, -1.1404e-01, -6.2448e-01,  7.6663e-01,\n",
       "           2.5437e+00, -1.2754e+00,  5.9238e-01],\n",
       "         [ 9.2344e-02, -4.7326e-01, -4.4466e-01,  9.1363e-01, -6.8500e-01,\n",
       "          -1.8172e-02, -1.4548e-01, -9.3719e-02],\n",
       "         [ 2.8568e-01,  4.5186e-01,  4.0175e-01, -1.5750e+00,  4.8697e-01,\n",
       "          -1.1552e+00, -1.7238e+00, -2.9940e-01],\n",
       "         [ 1.6789e+00,  8.3686e-01, -5.2856e-01, -1.4525e+00, -1.8704e-02,\n",
       "           5.3268e-01,  9.4951e-01,  6.2502e-01],\n",
       "         [ 1.7999e-01,  9.7200e-03,  8.2123e-01, -1.6683e-01,  8.9062e-01,\n",
       "          -4.7869e-01, -1.2686e+00,  1.0657e+00],\n",
       "         [ 5.3221e-01, -9.2501e-01,  4.3613e-01,  5.2507e-01, -1.5485e+00,\n",
       "           1.0482e+00, -4.9792e-01, -2.8189e-01],\n",
       "         [-1.3275e+00, -1.5133e+00, -9.6214e-01,  1.0482e+00, -3.4015e-01,\n",
       "          -3.3783e+00, -6.9494e-01, -2.6418e-02],\n",
       "         [-2.8089e+00, -4.4674e-01,  7.2110e-02,  1.4576e-02, -7.4149e-01,\n",
       "           1.0829e+00, -1.9069e-01,  3.8872e-01],\n",
       "         [-5.0971e-01, -1.5146e+00, -9.9172e-01,  9.7526e-01,  9.8697e-01,\n",
       "           1.3466e+00,  7.8452e-01, -1.4761e+00],\n",
       "         [-7.9606e-01, -1.1383e-01, -7.7543e-01,  2.3868e-01, -2.4282e-02,\n",
       "           9.5443e-01, -5.9788e-01,  1.3124e+00],\n",
       "         [-5.7090e-01, -1.2908e+00,  1.0436e+00,  3.9930e-01,  2.0349e+00,\n",
       "          -1.6488e-01,  6.0769e-01,  4.4168e-01],\n",
       "         [-4.9328e-01,  1.3218e+00,  1.5227e+00, -1.7717e-01,  8.4116e-01,\n",
       "           2.6361e+00,  1.0827e+00, -1.0027e+00],\n",
       "         [-8.4156e-01,  1.2315e+00, -1.1932e+00,  6.9344e-01, -4.3615e-01,\n",
       "           1.4795e-01, -9.1929e-01,  1.7404e-01],\n",
       "         [ 2.6129e-01, -1.8517e+00,  1.4082e+00,  1.1945e-01, -4.8768e-01,\n",
       "           3.1205e-01, -5.4738e-01,  9.9576e-01],\n",
       "         [-6.4609e-01,  1.2797e+00,  6.0636e-01, -2.2130e+00, -5.1212e-01,\n",
       "          -8.9900e-01, -1.4050e+00, -5.5865e-02],\n",
       "         [ 1.9880e+00,  5.3890e-01, -6.2407e-01,  4.6755e-01, -3.6215e-01,\n",
       "          -4.7737e-01,  2.9326e-01, -1.9623e+00],\n",
       "         [ 7.1059e-01,  2.4899e-01,  2.0022e-03,  1.1171e-01,  7.0398e-01,\n",
       "          -2.7869e-01,  4.5955e-01,  5.9393e-01],\n",
       "         [-4.5911e-01,  1.5432e+00, -1.5809e-01,  8.0768e-01, -2.2853e+00,\n",
       "           1.8900e-01,  6.1683e-01, -1.6926e+00],\n",
       "         [-1.2761e+00, -4.2891e-01,  1.0299e+00, -1.0723e+00,  8.9172e-02,\n",
       "           3.9183e-01,  9.2318e-01, -1.1792e-01],\n",
       "         [ 3.1573e-01, -3.8985e-02, -1.1328e+00,  5.7251e-01,  5.3000e-01,\n",
       "          -3.5246e-02, -8.8565e-01,  1.3766e-02],\n",
       "         [ 2.4712e+00,  3.6713e-01, -1.2850e+00,  7.4262e-01, -1.1275e+00,\n",
       "           1.5359e+00, -2.0350e+00,  7.4428e-01],\n",
       "         [-1.0844e-01,  3.6536e-01, -5.1341e-01, -1.0460e+00,  6.8030e-01,\n",
       "          -1.5936e+00, -5.9952e-03,  1.7311e+00],\n",
       "         [ 1.1051e+00,  9.9990e-01, -3.7615e-01, -6.8507e-01, -1.6208e+00,\n",
       "           7.0685e-01,  1.1353e+00,  1.4132e+00],\n",
       "         [-1.5632e+00,  1.5882e+00,  1.1077e+00,  4.0072e-01, -1.3048e+00,\n",
       "           1.3297e-02,  5.2154e-01,  1.7670e+00],\n",
       "         [-4.7245e-01,  2.2152e-02,  4.2107e-01,  1.5452e+00,  1.1016e+00,\n",
       "           5.6662e-02,  2.3900e-01,  7.9181e-01],\n",
       "         [ 7.4043e-02, -3.7562e-01, -1.0176e+00,  1.5926e+00,  6.0652e-02,\n",
       "           1.6701e+00, -4.8886e-01,  9.0556e-01],\n",
       "         [ 1.2867e+00, -7.5416e-01,  3.4622e-01,  6.0267e-01, -3.1682e-01,\n",
       "          -1.1445e+00, -1.8824e+00,  1.5957e+00],\n",
       "         [ 7.9669e-01,  3.3578e-01, -2.5578e-01,  1.5472e+00, -1.7726e+00,\n",
       "          -2.6021e-01,  7.6176e-01, -6.4627e-01],\n",
       "         [ 1.6178e+00, -1.8636e+00, -1.7699e+00,  1.8531e+00, -8.5066e-01,\n",
       "          -6.2715e-01, -7.7490e-01, -7.4551e-01],\n",
       "         [-1.0926e-01, -1.9855e-01,  6.1566e-03, -7.7995e-01,  7.8403e-02,\n",
       "          -1.4821e+00,  1.7478e+00,  4.4394e-01],\n",
       "         [-2.9686e-01, -7.2379e-02, -1.1126e-01,  1.4843e+00, -1.8954e+00,\n",
       "          -5.5271e-01,  1.2766e+00, -3.4921e-02],\n",
       "         [ 1.6324e+00,  2.9492e-01,  1.6094e+00, -3.3385e-01,  6.5358e-01,\n",
       "           4.7906e-01,  1.3170e+00,  1.4238e+00],\n",
       "         [-9.0574e-01, -4.2383e-01, -7.3242e-01, -6.8994e-01, -2.3394e-01,\n",
       "          -1.1066e+00, -1.1681e+00, -2.3457e-01],\n",
       "         [-1.1124e-01,  8.0335e-01, -6.5814e-02,  1.1907e-01,  1.3917e+00,\n",
       "           6.5342e-02, -1.6723e-01,  5.9300e-01],\n",
       "         [-3.2543e-01, -1.3238e+00, -5.8171e-02,  3.9265e-01, -1.1306e-01,\n",
       "          -1.3495e+00, -2.9880e-01, -1.0781e+00],\n",
       "         [-5.1871e-02, -2.1369e+00,  1.8174e+00, -2.9330e-01,  1.6317e-01,\n",
       "           1.4631e-01, -1.5392e+00,  6.0293e-01],\n",
       "         [-1.0259e+00,  2.6607e+00, -5.0964e-01,  6.8357e-01, -2.9048e-01,\n",
       "           1.9681e-01,  1.4518e+00,  2.9555e-01],\n",
       "         [-2.1062e-01, -1.7674e+00,  4.0227e-01, -6.0403e-03,  1.5437e+00,\n",
       "          -6.9528e-01, -2.0117e-01, -4.4920e-01],\n",
       "         [ 2.7374e+00, -5.1314e-02,  7.7903e-01,  2.2077e+00, -1.0726e+00,\n",
       "           1.3834e+00, -1.5509e+00, -7.5965e-01],\n",
       "         [-9.1868e-02, -1.4063e+00,  2.5617e+00, -1.1175e+00,  1.3828e-01,\n",
       "          -1.4911e+00,  1.1544e+00,  8.8782e-02],\n",
       "         [-8.0475e-02,  2.0728e+00,  1.7347e-01, -1.2466e-01,  4.5138e-01,\n",
       "           5.1632e-01, -1.4630e-02, -3.5852e-01],\n",
       "         [-8.2575e-01,  5.2121e-01, -1.7810e+00,  1.9212e+00, -1.2682e+00,\n",
       "           1.3881e+00,  1.3623e-03, -7.4241e-01],\n",
       "         [-1.6802e+00, -2.1634e+00,  6.4602e-01, -2.3654e+00, -1.8783e+00,\n",
       "          -5.3929e-01, -1.1307e+00, -1.7484e+00],\n",
       "         [-6.1886e-02, -9.7255e-01, -1.1350e+00, -6.0645e-01,  1.1235e+00,\n",
       "           1.0302e-01, -1.7433e-01,  8.7117e-01],\n",
       "         [ 1.0404e+00, -4.3983e-02, -1.1329e+00,  1.6324e+00, -1.7275e-01,\n",
       "           1.0401e+00, -1.4180e-01,  7.3396e-01],\n",
       "         [ 2.0011e+00, -2.7073e+00,  1.2628e+00, -1.6894e+00,  2.9595e-02,\n",
       "           1.9625e+00,  4.5373e-02, -3.6155e+00],\n",
       "         [-9.9772e-01,  4.6266e-01, -1.5182e+00,  1.2443e+00, -9.4850e-01,\n",
       "          -7.0617e-01,  1.8516e+00,  1.4274e+00],\n",
       "         [-4.3005e-01,  1.5542e+00,  3.5875e-01,  7.1699e-01, -1.6924e-01,\n",
       "           1.2965e-01, -1.9281e+00, -7.9091e-01],\n",
       "         [-7.3138e-01, -6.7383e-01,  3.0052e-01,  1.8579e+00, -9.6394e-01,\n",
       "          -2.9923e-01,  1.6813e+00, -1.2837e+00],\n",
       "         [-3.9493e-01, -3.3197e-01, -1.2579e-01,  1.4346e+00, -8.0454e-01,\n",
       "           9.0407e-01,  7.8732e-01, -3.7597e-01],\n",
       "         [-1.0828e+00, -5.3712e-01,  1.7632e+00, -1.6255e+00,  1.4831e+00,\n",
       "           1.4939e+00, -2.1564e+00,  8.3334e-01],\n",
       "         [ 3.1747e-01,  5.5338e-01, -9.3946e-01,  6.5215e-01, -8.2014e-02,\n",
       "           8.2541e-01, -9.8081e-02, -1.6785e-01],\n",
       "         [-1.5774e-01,  1.9474e+00, -1.1472e-01, -8.8135e-01, -9.4090e-01,\n",
       "          -1.3633e+00, -6.5661e-01, -3.2479e-01],\n",
       "         [ 1.1778e+00, -1.0403e-01, -1.3000e+00, -5.2762e-01,  1.2440e-02,\n",
       "           1.4844e+00,  4.0333e-01,  8.5894e-01],\n",
       "         [ 1.1494e-03,  7.4993e-01,  4.5620e-01, -4.9081e-01,  5.9799e-01,\n",
       "           7.4944e-01,  4.6221e-01, -9.7611e-01],\n",
       "         [-2.3244e+00,  1.0547e+00,  1.1592e+00,  1.7309e+00, -9.6787e-01,\n",
       "          -1.3161e+00, -2.0711e-01, -1.5025e-02],\n",
       "         [ 1.6254e+00,  8.6767e-01,  7.8979e-01, -7.6485e-01,  9.1577e-02,\n",
       "           1.7455e-01, -1.3542e+00,  1.4120e+00],\n",
       "         [ 1.7777e+00,  4.4635e-01, -1.0154e+00,  9.5903e-01, -6.4178e-01,\n",
       "          -2.3186e-01, -6.5563e-01, -7.3872e-01],\n",
       "         [ 5.2210e-01,  1.4297e+00,  8.9852e-01, -1.3259e+00, -2.1224e-01,\n",
       "          -2.1170e+00, -8.3790e-01,  2.0001e-01],\n",
       "         [-1.7748e+00, -4.2457e-02, -2.0428e+00,  8.0564e-01,  7.5863e-01,\n",
       "           3.4184e-01,  1.1208e+00,  1.3828e+00],\n",
       "         [-8.2808e-01,  1.0501e+00, -1.6711e-01, -6.2360e-01,  1.4687e-01,\n",
       "           7.6216e-01,  6.6017e-01, -1.3289e+00],\n",
       "         [ 1.7662e+00,  7.9707e-01, -1.0036e-01,  5.6007e-01, -2.0622e+00,\n",
       "           1.8692e+00, -2.1720e-01,  1.5951e-01],\n",
       "         [-9.3459e-01, -5.8371e-01, -1.5231e+00, -8.2606e-01,  1.7719e+00,\n",
       "          -1.4837e+00,  1.1212e+00,  1.4388e+00],\n",
       "         [ 2.3886e+00,  5.3852e-01, -4.1032e-01,  4.0530e-01, -5.4928e-01,\n",
       "          -7.0691e-01,  2.3931e-01, -1.0168e+00]], requires_grad=True)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dbf5836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy2.n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9c0012e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([30, 8])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([5, 8]),\n",
       " torch.Size([15, 8]),\n",
       " torch.Size([8, 8]),\n",
       " torch.Size([10, 8]),\n",
       " torch.Size([8, 8])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9e88883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.1540, -0.7218, -0.6148, -1.1384,  0.7613,  0.5972,  1.1757,  0.3262],\n",
       "         [-1.4112, -0.2167,  0.3938, -1.4913,  1.3192,  1.7807,  0.6318,  0.6237],\n",
       "         [-0.1451, -0.6842,  1.1039,  1.3135, -0.5073, -0.8235,  2.0020, -0.1488],\n",
       "         [-0.2424, -0.0462, -0.3179,  0.3138,  0.6748,  0.2384, -0.6453,  0.7034],\n",
       "         [-0.2607, -0.9020,  0.5688,  0.6303,  0.3519, -0.6548, -0.3156, -0.4868],\n",
       "         [-0.2431, -0.7835, -0.2948, -0.2434, -0.0768,  1.0519,  0.2246, -0.1084],\n",
       "         [-1.0518, -0.9268,  0.1243,  0.4568, -1.3665, -0.1919, -0.1703, -0.6696],\n",
       "         [-0.2790,  0.4299, -1.9481, -1.1087, -0.7623, -0.0644, -0.7779, -0.2100],\n",
       "         [-0.5711,  0.1445, -0.4366,  0.8133, -0.8657,  0.1340, -0.0595,  0.6446],\n",
       "         [ 0.3880, -0.8258, -0.1995,  1.8843, -0.0441, -0.1333, -0.6502, -2.4939],\n",
       "         [-0.1505,  0.1489,  0.1173,  0.4487, -1.2165,  1.1628, -0.2519,  1.0652],\n",
       "         [-0.1718,  0.0894,  0.3358, -0.6802,  0.3324, -1.8100, -0.8311,  0.0949],\n",
       "         [ 0.5517,  1.1834,  0.6168,  0.3200, -1.2666,  0.8441,  0.6411, -0.2283],\n",
       "         [ 0.4502, -2.1352, -1.8898, -0.6020,  0.7675, -1.0013, -0.8422,  0.2717],\n",
       "         [-1.8047,  0.3746, -1.1880,  0.3900,  1.0331, -1.8727, -1.1369, -0.1032],\n",
       "         [ 1.5265,  0.6743,  1.2503, -0.7241,  0.6880,  0.2236,  1.6415, -0.9279],\n",
       "         [-0.1487, -1.4675,  0.0176,  0.9085, -0.0283, -0.6351, -0.0049,  0.3455],\n",
       "         [ 0.3219,  2.3126, -1.0980, -0.4288, -0.5413, -0.2988,  0.9671, -1.2169],\n",
       "         [-0.2355, -0.4859,  0.4048, -0.0360, -0.0072,  0.5289, -0.3580,  0.2462],\n",
       "         [ 1.5091, -0.7191,  1.7416,  1.1607, -0.0499, -0.3345, -0.8467,  0.3255],\n",
       "         [ 0.8351, -0.6059, -0.1857,  0.2785,  0.2885,  0.2783, -1.5034, -0.5070],\n",
       "         [ 0.6917, -0.2489, -0.3525, -0.1168, -0.5771, -0.6453, -0.7704,  0.4901],\n",
       "         [-0.3973,  0.2927, -0.6331,  0.2659, -1.3689,  1.0636, -0.7484, -0.6024],\n",
       "         [-1.1725,  1.1781,  0.2571,  1.1863, -0.5293,  0.3512,  0.1041,  1.7652],\n",
       "         [ 0.6135,  0.8128,  0.7842,  0.1325,  0.2227, -1.3447,  0.9105, -0.9527],\n",
       "         [ 1.7726,  1.7212, -1.9873,  0.8448, -0.2724,  1.7166, -1.1250, -1.4278],\n",
       "         [-0.8319,  2.3583, -1.1981,  0.5540,  1.5460, -0.8417, -1.1226,  0.2927],\n",
       "         [ 0.0772,  1.8111,  0.2633, -0.9637, -2.0454,  0.7891,  0.7738,  0.7513],\n",
       "         [ 0.5860,  1.8152, -0.4838, -0.3038,  0.8078,  2.0897, -0.1474,  0.1277],\n",
       "         [-0.5550, -1.2217, -0.5497,  0.9709,  1.1913, -0.6202,  0.2644,  1.2285]],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(testy3.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66f5f6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2893, -0.3387, -2.0279,  1.4775, -1.9654, -0.8746, -1.0473, -0.0404],\n",
       "         [ 1.1079, -0.9204,  2.0708,  2.5847,  0.1918,  1.0006,  1.5968,  0.0574],\n",
       "         [ 0.2249, -0.1487,  1.3111,  0.2367,  1.0392, -1.5631,  0.0610, -1.4645],\n",
       "         [-1.0008, -1.2130,  1.8167, -1.4363,  1.3627, -0.0217,  0.4467,  0.6003],\n",
       "         [-1.6215, -1.1435, -0.5937,  1.4604,  1.8629, -2.1059,  0.9321, -0.9182]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 6.8568e-01, -1.1671e+00, -9.8388e-01,  6.8550e-01, -1.3188e+00,\n",
       "          -1.8720e-01,  1.1237e-03,  6.3637e-01],\n",
       "         [-5.3990e-01, -1.0267e+00, -2.4589e-01,  7.3956e-01,  1.7770e-01,\n",
       "          -1.0731e-02, -2.2698e-01,  5.3248e-01],\n",
       "         [ 3.5325e-02,  2.0470e+00, -2.9228e-01,  6.8893e-01,  6.5434e-01,\n",
       "           1.4819e+00,  8.6990e-02,  8.6833e-01],\n",
       "         [-8.9699e-01,  2.0866e+00, -9.0367e-01, -2.2575e-01,  2.8444e-01,\n",
       "          -6.5209e-01, -9.7627e-01, -4.1419e-01],\n",
       "         [-2.5353e-01,  1.7534e+00,  2.0806e+00,  1.3584e-01,  8.7731e-01,\n",
       "          -8.2767e-01, -9.2080e-02, -2.1292e-01],\n",
       "         [ 4.8108e-01,  3.3654e-01, -4.1305e-01, -1.3271e+00, -2.2107e-01,\n",
       "          -3.9230e-01, -1.5202e-01,  9.2236e-01],\n",
       "         [ 9.6249e-02, -5.3647e-01, -2.5118e-01, -2.3094e+00, -6.0017e-01,\n",
       "           9.6661e-01,  2.0356e+00,  1.3843e+00],\n",
       "         [-3.7490e-02,  1.4161e+00, -4.8559e-01,  1.7607e+00,  1.4980e+00,\n",
       "          -4.9040e-01, -1.5431e+00,  8.4041e-02],\n",
       "         [ 1.1735e+00,  1.2670e+00,  9.3838e-01, -6.0083e-01, -1.3793e+00,\n",
       "          -8.5230e-01,  7.1993e-01,  6.4800e-01],\n",
       "         [-1.0871e-01,  1.6999e-01, -1.2031e+00, -2.9265e-01,  1.2105e-01,\n",
       "          -7.2564e-01, -6.2929e-01, -1.3607e+00],\n",
       "         [-7.8308e-01,  4.9993e-01,  1.1367e+00,  5.8459e-01, -8.8694e-01,\n",
       "          -1.0237e+00, -5.3556e-01,  3.7395e-01],\n",
       "         [ 1.7005e+00, -5.7243e-02,  6.9048e-01, -4.3945e-01,  5.4998e-01,\n",
       "           2.8943e-01, -1.5260e-01,  9.9992e-01],\n",
       "         [ 2.0127e-01, -2.4845e+00, -1.4728e+00, -8.2178e-01, -3.1239e-01,\n",
       "          -6.9666e-01, -8.3648e-01,  3.9622e-01],\n",
       "         [-1.9016e+00,  1.7920e-01,  7.4716e-05,  5.2896e-01, -1.0491e+00,\n",
       "          -5.1151e-02, -8.0765e-01, -4.1695e-01],\n",
       "         [ 4.6633e-02,  1.3562e+00, -6.2173e-01,  1.2020e+00, -3.6604e-01,\n",
       "          -6.9363e-01,  4.5322e-01,  1.2214e+00]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.3470,  0.2758,  0.0789,  0.1543,  0.3452,  0.0526, -0.3436,  0.1118],\n",
       "         [ 0.0248, -0.3453,  0.3038,  0.1207, -0.0942, -0.2343,  0.0107,  0.1360],\n",
       "         [-0.0312, -0.1617, -0.2385, -0.0879,  0.3234, -0.2773,  0.1436,  0.0380],\n",
       "         [-0.1608, -0.0626, -0.0594,  0.2816,  0.2507,  0.1059, -0.1487, -0.2145],\n",
       "         [-0.1788, -0.3531,  0.2981,  0.2726, -0.2585,  0.1134,  0.1424,  0.0303],\n",
       "         [ 0.0957, -0.2872,  0.2265, -0.0305,  0.3244,  0.2314,  0.2039,  0.1359],\n",
       "         [ 0.2944, -0.0599, -0.2085, -0.0368,  0.0049, -0.1232, -0.1909,  0.0725],\n",
       "         [ 0.1396, -0.3013, -0.1909, -0.1572, -0.2535, -0.2844, -0.2196,  0.0397]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0418,  0.0653,  0.4908,  1.0884,  1.1189, -0.5705, -1.6630,  1.1394],\n",
       "         [-2.0566, -0.5032, -0.2164,  0.0377, -1.0101, -1.0025,  0.1523, -0.5624],\n",
       "         [-1.3976,  0.1151, -0.9497,  0.1093,  1.3788,  0.6827,  0.7607, -0.3295],\n",
       "         [ 0.4226,  1.3085, -1.7351,  0.5086, -0.7654,  0.9819, -0.7399, -1.5430],\n",
       "         [ 1.1570,  1.9940,  0.2132, -0.3094, -1.7629,  0.0909, -0.4457, -0.0510],\n",
       "         [-1.4817, -0.3688,  0.2627,  2.2342, -1.1306, -0.4053, -0.7423, -0.9059],\n",
       "         [ 0.2998,  0.7066,  0.4723,  2.6012, -0.7173, -1.8061, -0.7783,  0.5350],\n",
       "         [ 1.4953, -1.0296,  1.1401,  0.7218,  0.6861, -0.1569,  0.0441,  0.3684],\n",
       "         [-0.0642, -0.0469,  1.3179, -2.2715, -1.1988,  0.2644, -0.1077, -0.3159],\n",
       "         [ 0.2473, -2.0321, -0.6394,  0.0119, -1.0327, -0.8106, -0.5196,  0.9126]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1731, -0.3293, -0.2445,  0.1375,  0.1156, -0.3094,  0.1044,  0.0573],\n",
       "         [-0.1306, -0.0340,  0.1483, -0.3496,  0.2507,  0.3476,  0.2789, -0.1638],\n",
       "         [ 0.0587,  0.2271,  0.3436,  0.3476, -0.2596,  0.2614, -0.2058, -0.3248],\n",
       "         [-0.2242, -0.0440, -0.1973, -0.1423,  0.2492, -0.3504,  0.0857,  0.0366],\n",
       "         [ 0.0938,  0.1544, -0.3119, -0.2147, -0.0284,  0.2339, -0.0565, -0.2522],\n",
       "         [-0.1924,  0.2671,  0.2020, -0.0315,  0.2641,  0.2121, -0.0332,  0.3349],\n",
       "         [-0.1821, -0.0883, -0.2530, -0.0728, -0.3505, -0.3016, -0.0774,  0.0145],\n",
       "         [-0.1536,  0.2136,  0.1998,  0.1556,  0.2623,  0.0473,  0.2521,  0.2933]],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(testy4.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61064028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81104fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3c899c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81bedcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18*2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb258b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11400*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b568978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688176"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "43011*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a3370f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1482.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.13*11400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d717531b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07017543859649122"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "800/11400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5a2dd0",
   "metadata": {},
   "source": [
    "## Import Blur modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ebc4522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from blur import init_config_run, Config, Trainer, ScheduledOptimizer\n",
    "from blur import Blur, DecoderXL, AdaptiveInput, AdaptiveLogSoftmaxWithLoss, DecoderFT\n",
    "from blur.processing import get_lm_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d26b598",
   "metadata": {},
   "source": [
    "## Define model and training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d0f68ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Define config paths\n",
    "###############################################################################\n",
    "\n",
    "config_dir = os.path.join('configs', 'xl')\n",
    "config_run_path = os.path.join(config_dir, 'config_run.json')\n",
    "config_encoder_path = os.path.join(config_dir, 'config_encoder.json')\n",
    "config_decoder_path = os.path.join(config_dir, 'config_decoder.json')\n",
    "\n",
    "###############################################################################\n",
    "# Load config files\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "config_model = Config(**{\"tgt_len\": 200, \"mem_len\": 150, \"ext_len\": 0})\n",
    "config_run = init_config_run(config_run=Config.from_json(config_run_path), config_model=config_model)\n",
    "config_encoder = Config.from_json(config_encoder_path)\n",
    "config_decoder = Config.from_json(config_decoder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcf233a",
   "metadata": {},
   "source": [
    "## Set parameters for sandbox testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce0deb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "config_run.multi_gpu = False\n",
    "config_run.max_step = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c206c0",
   "metadata": {},
   "source": [
    "## Load data and set vocabulary length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cc8d22",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cfe3da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_decoder.nft = 0\n",
    "# config_decoder.nxl = 16\n",
    "# config_decoder.ft_first = False\n",
    "\n",
    "# ###############################################################################\n",
    "# # Build the model\n",
    "# ###############################################################################\n",
    "\n",
    "# corpus = get_lm_corpus(config_run.data, config_run.dataset)\n",
    "# config_encoder.n_classes = len(corpus.vocab)\n",
    "\n",
    "# model = Blur(\n",
    "#     **config_model.parameters(),\n",
    "#     encoder = AdaptiveInput(**config_encoder.parameters()),\n",
    "#     decoder = DecoderFT(**config_decoder.parameters()),\n",
    "#     lm_loss = AdaptiveLogSoftmaxWithLoss(**config_encoder.parameters()),\n",
    "# )\n",
    "# trainer = Trainer(config_run = config_run, device = device)\n",
    "\n",
    "# pass;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f54f792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dataset...\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Build the model\n",
    "###############################################################################\n",
    "\n",
    "corpus = get_lm_corpus(config_run.data, config_run.dataset)\n",
    "config_encoder.n_classes = len(corpus.vocab)\n",
    "\n",
    "model = Blur(\n",
    "    tgt_len = 150, mem_len = 150, ext_len = 0,\n",
    "    encoder = AdaptiveInput(**config_encoder.parameters()),\n",
    "    decoder = DecoderXL(**config_decoder.parameters()),\n",
    "    lm_loss = AdaptiveLogSoftmaxWithLoss(**config_encoder.parameters()),\n",
    ")\n",
    "trainer = Trainer(config_run = config_run, device = device)\n",
    "\n",
    "pass;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330c0bf",
   "metadata": {},
   "source": [
    "## Load some example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4812e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from blur.training import StreamDataset, StreamCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7d3f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = StreamDataset(\n",
    "    data=corpus.train, tgt_len=model.tgt_len, batch_size=config_run.batch_size)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set, batch_size=config_run.batch_size, shuffle=False,\n",
    "        num_workers=0, pin_memory=True, sampler=None, collate_fn=StreamCollator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56f34293",
   "metadata": {},
   "outputs": [],
   "source": [
    "detokenize_fn = np.vectorize(lambda x: corpus.vocab.idx2sym[x])\n",
    "\n",
    "iterdata = {}\n",
    "mems = tuple()\n",
    "\n",
    "for batch, (data, target) in enumerate(train_loader):\n",
    "    iterdata[batch] = (data, target, mems)\n",
    "    \n",
    "#     ret = model(data, target, *mems)\n",
    "#     loss, mems = ret[0], ret[1:]\n",
    "#     loss = loss.float().mean().type_as(loss)\n",
    "    \n",
    "    if batch>2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c5b1aa",
   "metadata": {},
   "source": [
    "## Inspect example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ca9195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 150])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterdata[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d5042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detokenize_fn(iterdata[0][1][0,:])[:50]\n",
    "# detokenize_fn(iterdata[0][1][1,:])[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91560de5",
   "metadata": {},
   "source": [
    "## Run data through model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "746edae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ba3d567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5597.078252812094"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(8.63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d523132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f127b78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n",
      "torch.Size([150, 150, 1]) torch.Size([150, 150, 8, 10])\n"
     ]
    }
   ],
   "source": [
    "output = model(*iterdata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7472e275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n",
      "torch.Size([150, 300, 1]) torch.Size([150, 300, 8, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output': torch.Size([150, 8, 410]), 'mems': 17, 'loss': torch.Size([150, 8])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(iterdata[1][0], iterdata[1][1], output['mems'])\n",
    "{k:v.shape if hasattr(v, 'shape') else len(v) for k,v in output.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5cb238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Define config paths\n",
    "###############################################################################\n",
    "\n",
    "config_dir = os.path.join('configs')\n",
    "config_run_path = os.path.join(config_dir, 'config_run.json')\n",
    "config_embedder_path = os.path.join(config_dir, 'config_adaptive.json')\n",
    "config_transformer_path = os.path.join(config_dir, 'config_xl.json')\n",
    "\n",
    "###############################################################################\n",
    "# Load config files\n",
    "###############################################################################\n",
    "\n",
    "config_run = init_config_run(config_run=Config.from_json(config_run_path), config_model=config_model)\n",
    "config_embedder = Config.from_json(config_embedder_path)\n",
    "config_transformer = Config.from_json(config_transformer_path)\n",
    "\n",
    "config_embedder.n_classes = len(corpus.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e35de87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<blur.utils.config.Config at 0x7fc190f452d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cb34aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_transformer.l_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef0d199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcde7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35b21595",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from collections import namedtuple\n",
    "from blur.utils.config import Config\n",
    "\n",
    "config_model_init = Config(\n",
    "    init='normal',\n",
    "    init_range=0.1,\n",
    "    init_std=0.02,\n",
    "    proj_init_std=0.01)\n",
    "\n",
    "def init_weight(weight):\n",
    "    if config_model_init.init == 'uniform':\n",
    "        nn.init.uniform_(weight, -config_model_init.init_range, config_model_init.init_range)\n",
    "    elif config_model_init.init == 'normal':\n",
    "        nn.init.normal_(weight, 0.0, config_model_init.init_std)\n",
    "\n",
    "def init_bias(bias):\n",
    "    nn.init.constant_(bias, 0.0)\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    if classname.find('AdaptiveInput') != -1:\n",
    "        if hasattr(m, 'emb_projs'):\n",
    "            for i in range(len(m.emb_projs)):\n",
    "                if m.emb_projs[i] is not None:\n",
    "                    nn.init.normal_(m.emb_projs[i], 0.0, 0.01)\n",
    "\n",
    "    elif classname.find('AdaptiveLogSoftmaxWithLoss') != -1:\n",
    "        if hasattr(m, 'cluster_weight') and m.cluster_weight is not None:\n",
    "            init_weight(m.cluster_weight)\n",
    "        if hasattr(m, 'cluster_bias') and m.cluster_bias is not None:\n",
    "            init_bias(m.cluster_bias)\n",
    "        if hasattr(m, 'out_projs'):\n",
    "            for i in range(len(m.out_projs)):\n",
    "                if m.out_projs[i] is not None:\n",
    "                    nn.init.normal_(m.out_projs[i], 0.0, 0.01)\n",
    "\n",
    "class BlurNew(nn.Module):\n",
    "    def __init__(self, embedder, transformer, predictor, tie_weight=True):\n",
    "        super(BlurNew, self).__init__()\n",
    "        self.embedder = embedder\n",
    "        self.transformer = transformer\n",
    "        self.predictor = predictor\n",
    "        self.output = namedtuple('BlurOutput', ['embedding', 'hiddens', 'loss'])\n",
    "\n",
    "        if tie_weight:\n",
    "            self._share_weights()\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def forward(self, x, y, output_hidden_states=False):\n",
    "        # x.shape = (b, l_q)\n",
    "        # y.shape = (b, l_q)\n",
    "\n",
    "\n",
    "        x = self.embedder(x)\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        x_output = x.output[..., -y.size(-1):, :]\n",
    "        x_output = self.predictor(x_output.view(-1, x_output.size(-1)), y.view(-1))\n",
    "        \n",
    "        output = (\n",
    "            x.output,\n",
    "            x.hiddens if output_hidden_states else None,\n",
    "            x_output.loss\n",
    "        )\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for p in self.transformer.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "        \n",
    "        self.embedder.apply(weights_init)\n",
    "        self.predictor.apply(weights_init)\n",
    "\n",
    "    def _share_weights(self):\n",
    "        # sharing the projection layers\n",
    "        for i in range(len(self.embedder.cutoffs) - 1):\n",
    "            self.embedder.tail[i][0].weight = self.predictor.tail[i][1].weight\n",
    "            self.embedder.tail[i][1].weight = torch.nn.Parameter(\n",
    "                self.predictor.tail[i][0].weight.transpose(0, 1)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4e2dc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from blur.models.shared import AdaptiveInput, AdaptiveLogSoftmaxWithLoss\n",
    "from blur.models.xl.xl import Xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a1e69c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93a93876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_classes': 267735,\n",
       " 'd_model': 410,\n",
       " 'div_value': 1,\n",
       " 'cutoffs': [20000, 40000, 200000],\n",
       " 'tail_drop': 0.1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_embedder.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd281841",
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel = BlurNew(\n",
    "    embedder = AdaptiveInput(**config_embedder.parameters()),\n",
    "    transformer = Xl(**config_transformer.parameters()),\n",
    "    predictor = AdaptiveLogSoftmaxWithLoss(**config_embedder.parameters())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1b5f34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n",
      "torch.Size([8, 10, 150, 150]) torch.Size([1, 1, 150, 150])\n",
      "torch.Size([8, 10, 150, 150])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-12.6764,   1.2672,   4.9045,  ...,  -4.3041,  -7.8463,   6.3880],\n",
       "          [-20.7601,   0.7232,  -6.6415,  ...,  15.3525,  -8.9451,  25.7931],\n",
       "          [-31.1605,   8.7146,   1.0645,  ...,  15.5846,  -4.3022,  22.8568],\n",
       "          ...,\n",
       "          [-58.6714,  -0.3401, -31.5972,  ...,   1.0591,  58.0678,   6.6044],\n",
       "          [ -1.0998,  -3.2383,   0.4504,  ...,  17.2961,  14.1097,   1.6420],\n",
       "          [-40.8924,  19.8200, -16.6184,  ...,  35.0438,  25.3558,  40.9212]],\n",
       " \n",
       "         [[ -1.1892,  -2.5506,   9.3387,  ...,  14.5104, -17.5101,   4.8578],\n",
       "          [-17.6027,  -7.5344, -13.1974,  ...,  18.6181,   4.4314,   7.1723],\n",
       "          [-16.0275,  -6.3602,  16.1223,  ...,  17.2019, -14.9662,   6.9135],\n",
       "          ...,\n",
       "          [-55.8978,  -3.9704, -17.9528,  ...,  16.5251,  -7.2139, -22.4423],\n",
       "          [-19.0504, -25.1625,  24.8741,  ..., -22.6481,  47.5699,   3.0002],\n",
       "          [ -0.3064, -71.0122, -11.3295,  ..., -26.9428,  10.9027, -15.8280]],\n",
       " \n",
       "         [[  6.1845,   7.4325,   9.3896,  ...,  14.6132, -12.5625,  20.3429],\n",
       "          [-22.9344,  18.4651,   9.3003,  ...,  16.1118,  -5.7318,   9.4315],\n",
       "          [-10.1600,  -4.7992,  11.8382,  ...,  19.0801, -14.1897,  13.6920],\n",
       "          ...,\n",
       "          [-67.9172,  28.1834,   5.5250,  ...,  16.9130,  42.8691,  15.4825],\n",
       "          [-34.2110,  52.9886, -16.2526,  ...,  38.5103, -13.8291,  45.8014],\n",
       "          [-51.7412,  44.5569,   5.7085,  ...,  -6.9782,  47.9258,  34.9215]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ -4.5274, -14.0297, -13.3892,  ...,  -5.2274,   0.7173,  26.4642],\n",
       "          [-22.7810,   0.2481,   1.1103,  ...,  -8.8281,  -3.0623,   7.6908],\n",
       "          [-34.9554,   1.3747,  -0.2773,  ...,   2.9019,   4.2899,  19.6873],\n",
       "          ...,\n",
       "          [-24.1040,  19.3272, -39.6785,  ...,  -5.8620,  24.5528,  46.4849],\n",
       "          [ -8.7536,  41.7056, -49.4564,  ..., -18.3713,  36.6798,  34.1765],\n",
       "          [-67.5693,   8.4962,  18.6696,  ..., -13.3437,  21.0484,  51.0530]],\n",
       " \n",
       "         [[-29.5672,  -3.1576,  -2.6384,  ...,  15.9119,  -6.7316,  11.7657],\n",
       "          [-17.2059,   0.8911,   6.2019,  ...,  16.9942,  -2.8318,  10.0491],\n",
       "          [-14.9864,  -2.4218,   8.4179,  ...,  15.8005,  -6.4353,  13.2217],\n",
       "          ...,\n",
       "          [-37.4144,   0.5233,  10.4555,  ...,  58.2387, -13.8580,  76.5805],\n",
       "          [-13.2669, -39.1269, -37.3182,  ...,   7.1415,  -5.8235, -15.0984],\n",
       "          [  8.7954,   5.0255, -11.6443,  ...,  12.5614,  11.3472,  11.0873]],\n",
       " \n",
       "         [[-22.7754,  -4.6103,  -9.5324,  ...,   4.8757,  -1.5983,  26.4032],\n",
       "          [-11.7850,  -6.1567,  -3.1895,  ...,  12.3191,  -5.7381,  19.9063],\n",
       "          [-18.5010,   0.4674,  -0.5052,  ...,  20.6568,  11.3205,  -5.2370],\n",
       "          ...,\n",
       "          [-12.4525,  -1.0928, -35.0006,  ...,   3.9302,   4.6666,  21.0817],\n",
       "          [  6.8340, -60.5197, -23.7111,  ..., -31.4161,  30.9454,  11.6530],\n",
       "          [-15.8746, -22.4048,   7.5970,  ..., -20.7309, -13.5107,  -1.8733]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " None,\n",
       " tensor(54.4132, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel(*iterdata[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8f2319e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'embedder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-7a15457c6d45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'embedder'"
     ]
    }
   ],
   "source": [
    "Blur(embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d9470b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_classes': 267735,\n",
       " 'd_model': 410,\n",
       " 'div_value': 1,\n",
       " 'cutoffs': [20000, 40000, 200000],\n",
       " 'tail_drop': 0.1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_embedder.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb472729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61828a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from blur.modeling.decoders.decoderfb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "474487fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "from blur.modeling.initializers import weights_init\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0bbcae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_model = Config(**{\"tgt_len\": 500, \"mem_len\": 100, \"ext_len\": 0})\n",
    "config_run = init_config_run(config_run=Config.from_json(config_run_path), config_model=config_model)\n",
    "config_encoder = Config.from_json(config_encoder_path)\n",
    "config_decoder = Config.from_json(config_decoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2e8f6275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dataset...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###############################################################################\n",
    "# Build the model\n",
    "###############################################################################\n",
    "\n",
    "corpus = get_lm_corpus(config_run.data, config_run.dataset)\n",
    "config_encoder.n_classes = len(corpus.vocab)\n",
    "\n",
    "model_fb = BlurFb(\n",
    "    **config_model.parameters(),\n",
    "    encoder = AdaptiveInput(**config_encoder.parameters()),\n",
    "    decoder = DecoderFb(**config_decoder.parameters()),\n",
    "    lm_loss = AdaptiveLogSoftmaxWithLoss(**config_encoder.parameters()),\n",
    ")\n",
    "trainer = Trainer(config_run = config_run, device = device)\n",
    "\n",
    "pass;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86d71def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "torch.Size([8, 200, 410]) torch.Size([8, 200])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output': torch.Size([200, 8, 410]), 'mems': 2, 'loss': torch.Size([200, 8])}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_fb = model_fb(*iterdata[0], return_memory=True)\n",
    "{k:v.shape if hasattr(v, 'shape') else len(v) for k,v in output_fb.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33dd88f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32])\n",
      "torch.Size([2, 32, 512])\n",
      "torch.Size([2, 32, 512])\n",
      "torch.Size([2, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "out1, mem1 = model(x1, return_memory = True)\n",
    "# out2, mem2 = model(x2, memory = mem1, return_memory = True)\n",
    "# out3, mem3 = model(x3, memory = mem2, return_memory = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d04a135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 20000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 20000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.shape\n",
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52974dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f69e7a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>449.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>396.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>362.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>322.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>288.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>244.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>237.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>214.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>198.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>187.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>193.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>174.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>164.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>164.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>154.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>150.047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         16\n",
       "0   540.074\n",
       "1   449.233\n",
       "2   396.448\n",
       "3   362.110\n",
       "4   322.791\n",
       "5   288.908\n",
       "6   256.375\n",
       "7   244.935\n",
       "8   237.264\n",
       "9   214.559\n",
       "10  198.868\n",
       "11  187.921\n",
       "12  193.113\n",
       "13  174.554\n",
       "14  164.466\n",
       "15  164.688\n",
       "16  154.171\n",
       "17  150.047"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbtranso[[16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "12b38fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbtransfo = pd.read_table(\n",
    "    glob.glob('LM-TFM-wt103/20210913-114436/*')[0], skiprows=3, header=None, delim_whitespace=True)\n",
    "fbtransfo['tFB - n_layer=8'] = fbtransfo[[16]]\n",
    "fbtransfo['num steps'] = fbtransfo[[4]]\n",
    "xltransfo = pd.read_table(\n",
    "    glob.glob('LM-TFM-wt103/20210913-114952/*')[0], skiprows=3, header=None, delim_whitespace=True)\n",
    "xltransfo['tXL - n_layer=16'] = xltransfo[[16]]\n",
    "xltransfo['num steps'] = xltransfo[[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "861fb719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='num steps'>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = xltransfo.plot('num steps', 'tXL - n_layer=16')\n",
    "fbtransfo.plot('num steps', 'tFB - n_layer=8', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac093f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
